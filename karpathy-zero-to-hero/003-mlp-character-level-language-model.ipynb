{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbouEmMaClr2LCi0M2hh4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tsilva/aiml-notebooks/blob/main/003-mlp-character-level-language-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP Character-Level Language Model\n",
        "\n",
        "This notebook is a personal reconstruction of Andrej Karpathy's lesson, [Building makemore Part 2: MLP](https://www.youtube.com/watch?v=TCH_1BHY58I). In this lesson, he improves on his previous lesson by building a flexible autoregressive character-level bigram language model using a [Multilayer Perceptron (MLP)](https://en.wikipedia.org/wiki/Multilayer_perceptron).\n",
        "\n",
        "*The purpose of this notebook is for my own self-learning, and shouldn't add much to the original lesson beyond extra verbosity. Parts of the notebook, namely the code snippets, may have been copied from the source lesson verbatim.*"
      ],
      "metadata": {
        "id": "4GxViqUuxgJj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Dataset üõ†Ô∏è\n",
        "\n",
        "First, let's download a list of names:"
      ],
      "metadata": {
        "id": "W8-wMFzdKtn6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IddmTztXHEzj",
        "outputId": "a1bef397-67ba-4d78-f8ed-4508669fcbfb"
      },
      "execution_count": 522,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-04 15:31:59--  https://raw.githubusercontent.com/karpathy/makemore/master/names.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 228145 (223K) [text/plain]\n",
            "Saving to: ‚Äònames.txt.7‚Äô\n",
            "\n",
            "\rnames.txt.7           0%[                    ]       0  --.-KB/s               \rnames.txt.7         100%[===================>] 222.80K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-09-04 15:31:59 (50.7 MB/s) - ‚Äònames.txt.7‚Äô saved [228145/228145]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now parse them into a list:"
      ],
      "metadata": {
        "id": "nQrinie1fxVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = open(\"names.txt\", \"r\").read().splitlines()\n",
        "words[:5]"
      ],
      "metadata": {
        "id": "dW5sxH_aHEOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e466974a-a793-4f5e-c1e5-13e4629c4c63"
      },
      "execution_count": 523,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia']"
            ]
          },
          "metadata": {},
          "execution_count": 523
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's assign a unique integer to each possible character found in the names we parsed:"
      ],
      "metadata": {
        "id": "Edljhq88fy_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list with all unique characters found in the raw data (sorted alphabetically)\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "\n",
        "# Create lookup table for converting each possible character to a unique integer\n",
        "stoi_map = {s:i+1 for i,s in enumerate(chars)}\n",
        "EOS_CHAR = \".\" # The character used to represent the end of a word\n",
        "EOS_CHAR_INDEX = 0\n",
        "stoi_map[EOS_CHAR] = EOS_CHAR_INDEX # Assign index zero to EOS char\n",
        "\n",
        "len(stoi_map), stoi_map"
      ],
      "metadata": {
        "id": "ITcKi_P9HN_h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9266cf71-a2e4-4981-9f0e-795750ec3317"
      },
      "execution_count": 524,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27,\n",
              " {'a': 1,\n",
              "  'b': 2,\n",
              "  'c': 3,\n",
              "  'd': 4,\n",
              "  'e': 5,\n",
              "  'f': 6,\n",
              "  'g': 7,\n",
              "  'h': 8,\n",
              "  'i': 9,\n",
              "  'j': 10,\n",
              "  'k': 11,\n",
              "  'l': 12,\n",
              "  'm': 13,\n",
              "  'n': 14,\n",
              "  'o': 15,\n",
              "  'p': 16,\n",
              "  'q': 17,\n",
              "  'r': 18,\n",
              "  's': 19,\n",
              "  't': 20,\n",
              "  'u': 21,\n",
              "  'v': 22,\n",
              "  'w': 23,\n",
              "  'x': 24,\n",
              "  'y': 25,\n",
              "  'z': 26,\n",
              "  '.': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 524
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now create a reverse lookup table to be able to convert the integers that represent each character back to the character itself:"
      ],
      "metadata": {
        "id": "--owMPBAmSe4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "itos_map = {i:s for s,i in stoi_map.items()}\n",
        "itos_map"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1xHf4whmXzC",
        "outputId": "6b618383-677a-48ee-d4d8-6b55b7ca6560"
      },
      "execution_count": 525,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'a',\n",
              " 2: 'b',\n",
              " 3: 'c',\n",
              " 4: 'd',\n",
              " 5: 'e',\n",
              " 6: 'f',\n",
              " 7: 'g',\n",
              " 8: 'h',\n",
              " 9: 'i',\n",
              " 10: 'j',\n",
              " 11: 'k',\n",
              " 12: 'l',\n",
              " 13: 'm',\n",
              " 14: 'n',\n",
              " 15: 'o',\n",
              " 16: 'p',\n",
              " 17: 'q',\n",
              " 18: 'r',\n",
              " 19: 's',\n",
              " 20: 't',\n",
              " 21: 'u',\n",
              " 22: 'v',\n",
              " 23: 'w',\n",
              " 24: 'x',\n",
              " 25: 'y',\n",
              " 26: 'z',\n",
              " 0: '.'}"
            ]
          },
          "metadata": {},
          "execution_count": 525
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now create the dataset we're going to use to train our model with. Given a sequence of $N$ characters, we want the model to predict the next character. Therefore, the input is going to be a list of $N$ characters, where each value in the list is the integer assigned to that character, and the output is the integer representing the next character.\n",
        "\n",
        "Let's create a dataset where the input is a sequence of $3$ characters. Let's use only a portion of the dataset to begin with, in this case with only the first $5$ words, as it will make experimentation faster for now:"
      ],
      "metadata": {
        "id": "C7Mu7qLrf0cV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# The default number of characters to use to predict the next character\n",
        "BLOCK_SIZE = 3\n",
        "\n",
        "def build_dataset(words, block_size=BLOCK_SIZE, verbose=False):\n",
        "  X, Y = [], [] # Initialize the dataset\n",
        "  for word in words:\n",
        "    if verbose: print(word)\n",
        "    context = [0] * block_size # Initialize the context with EOS characters\n",
        "    for char in word + EOS_CHAR: # For each character in the current word (plus the EOS stop character)\n",
        "      X.append(context) # Add the context accumulated so far as the input\n",
        "      char_i = stoi_map[char] # Convert the current character to an integer\n",
        "      Y.append(char_i) # Add the current character as the output (previous context must predict current character)\n",
        "      if verbose: print(f\"{''.join([itos_map[i] for i in context])} => {char}\")\n",
        "      context = context[1:] + [char_i] # Update the context by popping out the oldest character and pushing in the current one (FIFO buffer)\n",
        "\n",
        "  # Convert the dataset to tensors and return them\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  return X, Y\n",
        "\n",
        "# Create a dataset where each character is to be predicted based on\n",
        "# the last 3 characters, create it only using 5 words from the total dataset\n",
        "X, Y = build_dataset(words[:5], block_size=3, verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PI-cBxHbHejL",
        "outputId": "081b2c34-482f-4382-db1c-3e13b3f949b3"
      },
      "execution_count": 526,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "emma\n",
            "... => e\n",
            "..e => m\n",
            ".em => m\n",
            "emm => a\n",
            "mma => .\n",
            "olivia\n",
            "... => o\n",
            "..o => l\n",
            ".ol => i\n",
            "oli => v\n",
            "liv => i\n",
            "ivi => a\n",
            "via => .\n",
            "ava\n",
            "... => a\n",
            "..a => v\n",
            ".av => a\n",
            "ava => .\n",
            "isabella\n",
            "... => i\n",
            "..i => s\n",
            ".is => a\n",
            "isa => b\n",
            "sab => e\n",
            "abe => l\n",
            "bel => l\n",
            "ell => a\n",
            "lla => .\n",
            "sophia\n",
            "... => s\n",
            "..s => o\n",
            ".so => p\n",
            "sop => h\n",
            "oph => i\n",
            "phi => a\n",
            "hia => .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The input tensor $X$ is of shape $(32, 3)$ because the parsing of the $5$ words resulted in the collection of $32$ trigrams:"
      ],
      "metadata": {
        "id": "WW0Pe_JlP1km"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJV8ObAIPxgx",
        "outputId": "531f96af-cfa9-4d3b-e7ed-f1005cc06f72"
      },
      "execution_count": 527,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]),\n",
              " tensor([[ 0,  0,  0],\n",
              "         [ 0,  0,  5],\n",
              "         [ 0,  5, 13],\n",
              "         [ 5, 13, 13],\n",
              "         [13, 13,  1],\n",
              "         [ 0,  0,  0],\n",
              "         [ 0,  0, 15],\n",
              "         [ 0, 15, 12],\n",
              "         [15, 12,  9],\n",
              "         [12,  9, 22],\n",
              "         [ 9, 22,  9],\n",
              "         [22,  9,  1],\n",
              "         [ 0,  0,  0],\n",
              "         [ 0,  0,  1],\n",
              "         [ 0,  1, 22],\n",
              "         [ 1, 22,  1],\n",
              "         [ 0,  0,  0],\n",
              "         [ 0,  0,  9],\n",
              "         [ 0,  9, 19],\n",
              "         [ 9, 19,  1],\n",
              "         [19,  1,  2],\n",
              "         [ 1,  2,  5],\n",
              "         [ 2,  5, 12],\n",
              "         [ 5, 12, 12],\n",
              "         [12, 12,  1],\n",
              "         [ 0,  0,  0],\n",
              "         [ 0,  0, 19],\n",
              "         [ 0, 19, 15],\n",
              "         [19, 15, 16],\n",
              "         [15, 16,  8],\n",
              "         [16,  8,  9],\n",
              "         [ 8,  9,  1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 527
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output $Y$ tensor has shape $(32)$, containing one value representing the next character for each of the $32$ character sequences found in the input tensor $X$:"
      ],
      "metadata": {
        "id": "wV78_iW5P3IB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y.shape, Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk6c9QliP4tt",
        "outputId": "169ce193-1be6-428e-af5d-dd7eb441cb83"
      },
      "execution_count": 528,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32]),\n",
              " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "          1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 528
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Embeddings üîç\n",
        "\n",
        "To prepare character sequences for a neural network, it's important to avoid biases that can arise from sequential integer encoding, where higher numbers could imply greater importance (e.g., by propagating a stronger signal) or similarity (e.g., characters with close alphabetical positions might incorrectly be treated as more similar).\n",
        "\n",
        "One-hot encoding addresses this issue by representing each character with a unique binary vector where only one element is \"hot\" (set to $1$), and all others are \"cold\" (set to $0$). However, this method cannot capture any meaningful relationships between characters (e.g., the distinction between vowels and consonants) because each vector is orthogonal to the others and can't be adjusted during training.\n",
        "\n",
        "A more effective solution is to represent each character as a dense vector (embedding), where each character is mapped to a continuous vector with a smaller number of dimensions. Unlike one-hot encoding, these embeddings are not predefined but are instead learned during the training process along with other parameters, allowing the model to capture relationships and patterns within the data.\n",
        "\n",
        "Let's create a tensor `C` of shape $(27, 2)$ to serve as an embedding lookup table for the $27$ possible characters:"
      ],
      "metadata": {
        "id": "Xmcr4s48gDgR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((27, 2))\n",
        "C"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da47Co5ZJUVe",
        "outputId": "b90a143a-d016-4ee8-bbfd-d80daa3ad0f2"
      },
      "execution_count": 529,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.2061e-01, -2.2788e+00],\n",
              "        [-1.4616e-03,  9.9255e-01],\n",
              "        [ 1.8368e+00, -1.1358e+00],\n",
              "        [-4.3288e-01,  4.1514e-01],\n",
              "        [-1.9333e+00, -2.0084e-01],\n",
              "        [ 1.3398e+00,  9.7887e-01],\n",
              "        [ 2.5040e-01, -1.0362e+00],\n",
              "        [ 8.1175e-02,  1.7372e+00],\n",
              "        [-1.6380e-01,  2.8204e-01],\n",
              "        [-4.8332e-01,  1.0488e+00],\n",
              "        [ 1.6645e-01,  2.6210e-04],\n",
              "        [ 1.3086e+00, -1.3141e+00],\n",
              "        [ 3.1752e+00, -7.3441e-01],\n",
              "        [-1.8286e+00,  4.1638e-01],\n",
              "        [-6.1599e-01, -4.1060e-03],\n",
              "        [-1.3372e+00,  1.1549e+00],\n",
              "        [ 1.8801e+00, -4.0999e-01],\n",
              "        [ 2.4247e-01, -1.9184e+00],\n",
              "        [-1.3885e+00, -1.0694e+00],\n",
              "        [-9.1898e-01, -2.4123e+00],\n",
              "        [ 1.4326e+00, -3.0937e-01],\n",
              "        [ 4.5064e-01,  1.6974e+00],\n",
              "        [-4.8061e-01, -2.3162e+00],\n",
              "        [-4.0470e-01, -3.4926e-01],\n",
              "        [ 2.9875e+00, -1.3158e+00],\n",
              "        [ 1.1077e-01,  5.4974e-01],\n",
              "        [ 2.2322e+00,  1.2555e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 529
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could manually iterate through our $X$ tensor and swap all integer encoded characters with their respective embeddings, but it's much easier to do that with the power of PyTorch indexing, in fact, you can perform this replacement operation in a single call, let's learn how!"
      ],
      "metadata": {
        "id": "jGOCWLGAq1bU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know it's trivial to retrieve the embedding for a specific character:"
      ],
      "metadata": {
        "id": "lUt8Zo0QQm0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[5] # character \"e\" is represented by number \"5\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbCEIRkNJb8a",
        "outputId": "9ecf4b4b-8e75-4ee2-f547-526bfa2ed6af"
      },
      "execution_count": 530,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.3398, 0.9789])"
            ]
          },
          "metadata": {},
          "execution_count": 530
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And PyTorch allows retrieving multiple characters in one operation by providing a list of the indexes:"
      ],
      "metadata": {
        "id": "c9ZlbZhsQ92x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[[5,6,7]] # retrieve embeddings for character sequence: \"efg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8mBBESW1ZsU",
        "outputId": "871e5f30-d9c8-4601-dfba-0849b9eb7104"
      },
      "execution_count": 531,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3398,  0.9789],\n",
              "        [ 0.2504, -1.0362],\n",
              "        [ 0.0812,  1.7372]])"
            ]
          },
          "metadata": {},
          "execution_count": 531
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This index list could also be a tensor:"
      ],
      "metadata": {
        "id": "mnQ0iBaHRHJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([5,6,7])] # retrieve embeddings for character sequence: \"efg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWaoB29D1f25",
        "outputId": "d060175a-51ca-49bd-99da-d5ca0ab690a5"
      },
      "execution_count": 532,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3398,  0.9789],\n",
              "        [ 0.2504, -1.0362],\n",
              "        [ 0.0812,  1.7372]])"
            ]
          },
          "metadata": {},
          "execution_count": 532
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And the same value can be retrieved multiple times:"
      ],
      "metadata": {
        "id": "u0uhajsARJkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([5,6,7,7,7])] # retrieve embeddings for character sequence: \"efggg\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNgcfonB13km",
        "outputId": "09938b27-852d-4aca-a616-6694b1e3dd6b"
      },
      "execution_count": 533,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3398,  0.9789],\n",
              "        [ 0.2504, -1.0362],\n",
              "        [ 0.0812,  1.7372],\n",
              "        [ 0.0812,  1.7372],\n",
              "        [ 0.0812,  1.7372]])"
            ]
          },
          "metadata": {},
          "execution_count": 533
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch's powerful indexing allows you to work with N-dimensional tensors. The values in the lowest dimension of an indexing tensor are used as the indexes to access the target tensor:"
      ],
      "metadata": {
        "id": "yikpdJMFRNit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C[torch.tensor([[[5,6,7], [8,9,10]]])] # retrieve embeddings for character sequences: \"efg\", \"hij\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGtCTpQ915rN",
        "outputId": "dd50d697-b1ae-4573-b683-066143f71811"
      },
      "execution_count": 534,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.3398e+00,  9.7887e-01],\n",
              "          [ 2.5040e-01, -1.0362e+00],\n",
              "          [ 8.1175e-02,  1.7372e+00]],\n",
              "\n",
              "         [[-1.6380e-01,  2.8204e-01],\n",
              "          [-4.8332e-01,  1.0488e+00],\n",
              "          [ 1.6645e-01,  2.6210e-04]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 534
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use N-dimensional indexing to replace the integer encodings in our input tensor $X$ (which contains character sequences) with their corresponding embeddings. To demonstrate this, let's retrieve the embedding for a specific character from a single example sequence in tensor $X$:"
      ],
      "metadata": {
        "id": "8y8IC0d4RfzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "  X[13, 2], # retrieve integer encoding for 2nd character of 13th input character sequence\n",
        "  C[X][13, 2] # retrieve embedding for 2nd character of 13th input character sequence\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhHcJob62FdI",
        "outputId": "30e16c3f-59ca-452a-b954-749cd586c668"
      },
      "execution_count": 535,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1), tensor([-0.0015,  0.9925]))"
            ]
          },
          "metadata": {},
          "execution_count": 535
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now swap all our integer encodings with embeddings in one pass:"
      ],
      "metadata": {
        "id": "_nNMXzu-R44-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xemb = C[X]\n",
        "X.shape, Xemb.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is4eUjsH2bJD",
        "outputId": "9f4f38ab-59fa-45ce-cb20-07f4f238e3d4"
      },
      "execution_count": 536,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32, 3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 536
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We started with a `X` tensor of shape $(32, 3)$, that had $32$ character sequences, where each sequence had $3$ characters, each represented by an integer. As a result of the embedding lookup operation, we now have a `Xemb` tensor of shape $(32, 3, 2)$ because each of those integer encodings was replaced with its corresponding $2$-dimensional embedding."
      ],
      "metadata": {
        "id": "2WPi5InWSPL1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the MLP üß†\n",
        "\n",
        "A *Multilayer Perceptron* is a neural network that has at least one hidden layer. The one we're going to create will just have a single hidden layer, making it a $2$-layer network (hidden layer + output layer).\n",
        "\n",
        "The hidden layer will have $100$ neurons (this is an arbitrary value that can be adjusted), where each neuron is connected to $6$ inputs. The $6$ inputs are derived from sequences of $3$ characters, where each character is represented by a 2-dimensional embedding vector. This requires us to create a weight matrix `W1` of shape $(6, 100)$, which holds the weights for the connections between the inputs and the neurons. Additionally, we'll create a bias vector `b1` of shape $(100)$, containing a bias value for each neuron:"
      ],
      "metadata": {
        "id": "cpXWtkniSnlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W1 = torch.randn((6, 100)) # 6 inputs (3 characters * 2 dimensional embeddings) * 100 hidden neurons\n",
        "b1 = torch.randn(100) # number of biases equal to number of neurons"
      ],
      "metadata": {
        "id": "cOydxbEbMlXZ"
      },
      "execution_count": 537,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try running the *forward pass* through this layer:"
      ],
      "metadata": {
        "id": "f9h6eXfCTXwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try: Xemb @ W1 + b1\n",
        "except Exception as e: print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_IA7HSONWhw",
        "outputId": "2af123f8-4017-48d0-8c69-08aa4c8b8e4f"
      },
      "execution_count": 538,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mat1 and mat2 shapes cannot be multiplied (96x2 and 6x100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *forward pass* didn't work because the input has shape $(32, 3, 2)$ and the the layer has shape $(6, 100)$. If a matrix $A$ has shape $(m, n)$ and matrix $B$ has shape $(p, q)$, it is only possible to perform matrix multiplication $A \\times B$ if $n = p$, meaning that our input shape must be $(32, 6)$ for this operation to be possible."
      ],
      "metadata": {
        "id": "4Z79VTIVTcIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We aim to create a vector of length $6$ for the second dimension, which will contain all the embedding values for a $3$-character sequence in order.\n",
        "\n",
        "To retrieve the embedding for the first character in all sequences with a single call, recall that the `embeddings` tensor has a shape of $(32, 3, 2)$. The second dimension, with a length of $3$, represents the position of the characters in the sequence. By indexing a specific value in this dimension, we can extract the embeddings for that particular character position across all examples, without collapsing the other dimensions:"
      ],
      "metadata": {
        "id": "gZQi-PrmT4an"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = Xemb[:, 0, :] # Grab embeddings for 1st character from all 3-character input sequences\n",
        "t1.shape, t1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaOkXxfWOZey",
        "outputId": "7a8ec9ab-52c0-4526-c222-34b5ef482b74"
      },
      "execution_count": 539,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 2]),\n",
              " tensor([[-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [ 1.3398e+00,  9.7887e-01],\n",
              "         [-1.8286e+00,  4.1638e-01],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-1.3372e+00,  1.1549e+00],\n",
              "         [ 3.1752e+00, -7.3441e-01],\n",
              "         [-4.8332e-01,  1.0488e+00],\n",
              "         [-4.8061e-01, -2.3162e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-1.4616e-03,  9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.8332e-01,  1.0488e+00],\n",
              "         [-9.1898e-01, -2.4123e+00],\n",
              "         [-1.4616e-03,  9.9255e-01],\n",
              "         [ 1.8368e+00, -1.1358e+00],\n",
              "         [ 1.3398e+00,  9.7887e-01],\n",
              "         [ 3.1752e+00, -7.3441e-01],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-9.1898e-01, -2.4123e+00],\n",
              "         [-1.3372e+00,  1.1549e+00],\n",
              "         [ 1.8801e+00, -4.0999e-01],\n",
              "         [-1.6380e-01,  2.8204e-01]]))"
            ]
          },
          "metadata": {},
          "execution_count": 539
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result is a tensor of shape $(32, 2)$, representing the embeddings for the first character in each of the $32$ $3$-character sequences in the embedded input tensor. To retrieve the embeddings for all three characters in each sequence, we could simply perform this operation for each of the $3$ characters:"
      ],
      "metadata": {
        "id": "iMukBDP-3LGV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c0 = Xemb[:, 0, :] # For all character sequences, grab the embedding for the 1st character in the sequence\n",
        "c1 = Xemb[:, 1, :] # For all character sequences, grab the embedding for the 2nd character in the sequence\n",
        "c2 = Xemb[:, 2, :] # For all character sequences, grab the embedding for the 3rd character in the sequence\n",
        "c0.shape, c0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeBXIEvg54YS",
        "outputId": "b4c7c3e3-191b-4b1d-c2e3-2d85391f4c5d"
      },
      "execution_count": 540,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 2]),\n",
              " tensor([[-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [ 1.3398e+00,  9.7887e-01],\n",
              "         [-1.8286e+00,  4.1638e-01],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-1.3372e+00,  1.1549e+00],\n",
              "         [ 3.1752e+00, -7.3441e-01],\n",
              "         [-4.8332e-01,  1.0488e+00],\n",
              "         [-4.8061e-01, -2.3162e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-1.4616e-03,  9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.8332e-01,  1.0488e+00],\n",
              "         [-9.1898e-01, -2.4123e+00],\n",
              "         [-1.4616e-03,  9.9255e-01],\n",
              "         [ 1.8368e+00, -1.1358e+00],\n",
              "         [ 1.3398e+00,  9.7887e-01],\n",
              "         [ 3.1752e+00, -7.3441e-01],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00],\n",
              "         [-9.1898e-01, -2.4123e+00],\n",
              "         [-1.3372e+00,  1.1549e+00],\n",
              "         [ 1.8801e+00, -4.0999e-01],\n",
              "         [-1.6380e-01,  2.8204e-01]]))"
            ]
          },
          "metadata": {},
          "execution_count": 540
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have three tensors, each of shape $(32, 2)$, representing the embeddings for each character across all sequences, we can concatenate them along the columns (dimension $1$). This operation will combine the embeddings for each sequence into a single tensor of shape $(32, 6)$:"
      ],
      "metadata": {
        "id": "sNZxFk4iUgZv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_embedded = torch.cat([c0, c1, c2], dim=1) # Concatenate all tensors of shape (32, 2) along dimension 1, resulting in shape (32, 6) -- 2 + 2 + 2 = 6\n",
        "chars_embedded.shape, chars_embedded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KpiqlNJgOl9k",
        "outputId": "a06eb419-a72a-4f34-8c33-e598c1095ab8"
      },
      "execution_count": 541,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 6]),\n",
              " tensor([[-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00,  1.3398e+00,\n",
              "           9.7887e-01],\n",
              "         [-4.2061e-01, -2.2788e+00,  1.3398e+00,  9.7887e-01, -1.8286e+00,\n",
              "           4.1638e-01],\n",
              "         [ 1.3398e+00,  9.7887e-01, -1.8286e+00,  4.1638e-01, -1.8286e+00,\n",
              "           4.1638e-01],\n",
              "         [-1.8286e+00,  4.1638e-01, -1.8286e+00,  4.1638e-01, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.3372e+00,\n",
              "           1.1549e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -1.3372e+00,  1.1549e+00,  3.1752e+00,\n",
              "          -7.3441e-01],\n",
              "         [-1.3372e+00,  1.1549e+00,  3.1752e+00, -7.3441e-01, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [ 3.1752e+00, -7.3441e-01, -4.8332e-01,  1.0488e+00, -4.8061e-01,\n",
              "          -2.3162e+00],\n",
              "         [-4.8332e-01,  1.0488e+00, -4.8061e-01, -2.3162e+00, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [-4.8061e-01, -2.3162e+00, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -1.4616e-03,  9.9255e-01, -4.8061e-01,\n",
              "          -2.3162e+00],\n",
              "         [-1.4616e-03,  9.9255e-01, -4.8061e-01, -2.3162e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.8332e-01,  1.0488e+00, -9.1898e-01,\n",
              "          -2.4123e+00],\n",
              "         [-4.8332e-01,  1.0488e+00, -9.1898e-01, -2.4123e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-9.1898e-01, -2.4123e+00, -1.4616e-03,  9.9255e-01,  1.8368e+00,\n",
              "          -1.1358e+00],\n",
              "         [-1.4616e-03,  9.9255e-01,  1.8368e+00, -1.1358e+00,  1.3398e+00,\n",
              "           9.7887e-01],\n",
              "         [ 1.8368e+00, -1.1358e+00,  1.3398e+00,  9.7887e-01,  3.1752e+00,\n",
              "          -7.3441e-01],\n",
              "         [ 1.3398e+00,  9.7887e-01,  3.1752e+00, -7.3441e-01,  3.1752e+00,\n",
              "          -7.3441e-01],\n",
              "         [ 3.1752e+00, -7.3441e-01,  3.1752e+00, -7.3441e-01, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -9.1898e-01,\n",
              "          -2.4123e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -9.1898e-01, -2.4123e+00, -1.3372e+00,\n",
              "           1.1549e+00],\n",
              "         [-9.1898e-01, -2.4123e+00, -1.3372e+00,  1.1549e+00,  1.8801e+00,\n",
              "          -4.0999e-01],\n",
              "         [-1.3372e+00,  1.1549e+00,  1.8801e+00, -4.0999e-01, -1.6380e-01,\n",
              "           2.8204e-01],\n",
              "         [ 1.8801e+00, -4.0999e-01, -1.6380e-01,  2.8204e-01, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [-1.6380e-01,  2.8204e-01, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "           9.9255e-01]]))"
            ]
          },
          "metadata": {},
          "execution_count": 541
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main issue with this approach is that it's hardcoded for sequences that are exactly $3$ characters long. To make it more flexible and generalize it to sequences of any length, we can use `torch.unbind()` to split a tensor along a specified dimension:"
      ],
      "metadata": {
        "id": "JaNtGKglUoVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cn = torch.unbind(Xemb, dim=1)\n",
        "len(cn), cn[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muPhyv6O7tOw",
        "outputId": "96f76e2e-3779-4aeb-8134-e7e26e83a47b"
      },
      "execution_count": 542,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, torch.Size([32, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 542
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have the same $3$ tensors of shape $(32, 2)$ with a single call. Let's concatenate their rows:"
      ],
      "metadata": {
        "id": "mi5XzTUbU8_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chars_embedded = torch.cat(cn, dim=1) # Concatenate all tensors of shape (32, 2) along dimension 1 (columns), resulting in shape (32, 6) -- 2 + 2 + 2 = 6\n",
        "chars_embedded.shape, chars_embedded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAUynQxpPG-P",
        "outputId": "a7201eec-f988-4939-d65d-25914f9445ae"
      },
      "execution_count": 543,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 6]),\n",
              " tensor([[-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00,  1.3398e+00,\n",
              "           9.7887e-01],\n",
              "         [-4.2061e-01, -2.2788e+00,  1.3398e+00,  9.7887e-01, -1.8286e+00,\n",
              "           4.1638e-01],\n",
              "         [ 1.3398e+00,  9.7887e-01, -1.8286e+00,  4.1638e-01, -1.8286e+00,\n",
              "           4.1638e-01],\n",
              "         [-1.8286e+00,  4.1638e-01, -1.8286e+00,  4.1638e-01, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.3372e+00,\n",
              "           1.1549e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -1.3372e+00,  1.1549e+00,  3.1752e+00,\n",
              "          -7.3441e-01],\n",
              "         [-1.3372e+00,  1.1549e+00,  3.1752e+00, -7.3441e-01, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [ 3.1752e+00, -7.3441e-01, -4.8332e-01,  1.0488e+00, -4.8061e-01,\n",
              "          -2.3162e+00],\n",
              "         [-4.8332e-01,  1.0488e+00, -4.8061e-01, -2.3162e+00, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [-4.8061e-01, -2.3162e+00, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -1.4616e-03,  9.9255e-01, -4.8061e-01,\n",
              "          -2.3162e+00],\n",
              "         [-1.4616e-03,  9.9255e-01, -4.8061e-01, -2.3162e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.8332e-01,  1.0488e+00, -9.1898e-01,\n",
              "          -2.4123e+00],\n",
              "         [-4.8332e-01,  1.0488e+00, -9.1898e-01, -2.4123e+00, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-9.1898e-01, -2.4123e+00, -1.4616e-03,  9.9255e-01,  1.8368e+00,\n",
              "          -1.1358e+00],\n",
              "         [-1.4616e-03,  9.9255e-01,  1.8368e+00, -1.1358e+00,  1.3398e+00,\n",
              "           9.7887e-01],\n",
              "         [ 1.8368e+00, -1.1358e+00,  1.3398e+00,  9.7887e-01,  3.1752e+00,\n",
              "          -7.3441e-01],\n",
              "         [ 1.3398e+00,  9.7887e-01,  3.1752e+00, -7.3441e-01,  3.1752e+00,\n",
              "          -7.3441e-01],\n",
              "         [ 3.1752e+00, -7.3441e-01,  3.1752e+00, -7.3441e-01, -1.4616e-03,\n",
              "           9.9255e-01],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "          -2.2788e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -9.1898e-01,\n",
              "          -2.4123e+00],\n",
              "         [-4.2061e-01, -2.2788e+00, -9.1898e-01, -2.4123e+00, -1.3372e+00,\n",
              "           1.1549e+00],\n",
              "         [-9.1898e-01, -2.4123e+00, -1.3372e+00,  1.1549e+00,  1.8801e+00,\n",
              "          -4.0999e-01],\n",
              "         [-1.3372e+00,  1.1549e+00,  1.8801e+00, -4.0999e-01, -1.6380e-01,\n",
              "           2.8204e-01],\n",
              "         [ 1.8801e+00, -4.0999e-01, -1.6380e-01,  2.8204e-01, -4.8332e-01,\n",
              "           1.0488e+00],\n",
              "         [-1.6380e-01,  2.8204e-01, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "           9.9255e-01]]))"
            ]
          },
          "metadata": {},
          "execution_count": 543
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We obtained our desired tensor of shape $(32, 6)$ using a straightforward method, but there's an even more efficient way to achieve this by utilizing the `view()` function in tensors.\n",
        "\n",
        "Let's create a simpler example to illustrate how this works:"
      ],
      "metadata": {
        "id": "doO9fdBVVILZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.arange(18)\n",
        "t.shape, t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5Ed70TUPejU",
        "outputId": "3f779751-e7a6-47e2-b8b0-ce6b2ab561cf"
      },
      "execution_count": 544,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([18]),\n",
              " tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17]))"
            ]
          },
          "metadata": {},
          "execution_count": 544
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tensor `t` has a shape of $(18)$, but it can easily be reshaped to any other form, as long as the product of all dimensions still equals $18$. For example, we can reshape it to have a shape of $(2, 9)$:"
      ],
      "metadata": {
        "id": "PqNiyD1_5Wbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.view(2, 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOjYTRqZPjC3",
        "outputId": "fc427c31-9820-4fcb-a463-82560f556eb8"
      },
      "execution_count": 545,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8],\n",
              "        [ 9, 10, 11, 12, 13, 14, 15, 16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 545
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or reshape it to $(9, 2)$:"
      ],
      "metadata": {
        "id": "1NFrkUlf6pX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.view(9, 2)"
      ],
      "metadata": {
        "id": "zAsxs-iL6z84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee64b61-94df-4cc5-e7cb-e87459fe0341"
      },
      "execution_count": 546,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0,  1],\n",
              "        [ 2,  3],\n",
              "        [ 4,  5],\n",
              "        [ 6,  7],\n",
              "        [ 8,  9],\n",
              "        [10, 11],\n",
              "        [12, 13],\n",
              "        [14, 15],\n",
              "        [16, 17]])"
            ]
          },
          "metadata": {},
          "execution_count": 546
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Or even reshape it to $(3, 3, 2)$:"
      ],
      "metadata": {
        "id": "I9r_wLRh6sJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.view(3, 3, 2)"
      ],
      "metadata": {
        "id": "qe7FyZA66urr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081fc36c-eaef-4569-ceaf-9fdf115707eb"
      },
      "execution_count": 547,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1],\n",
              "         [ 2,  3],\n",
              "         [ 4,  5]],\n",
              "\n",
              "        [[ 6,  7],\n",
              "         [ 8,  9],\n",
              "         [10, 11]],\n",
              "\n",
              "        [[12, 13],\n",
              "         [14, 15],\n",
              "         [16, 17]]])"
            ]
          },
          "metadata": {},
          "execution_count": 547
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This operation not only simplifies the process but is also highly efficient because it doesn't create any new tensors, thus avoiding additional memory allocation.\n",
        "\n",
        "The reason this works is that tensors are stored in memory as sequential arrays and are accessed differently based on certain parameters that dictate how the data is interpreted. For more details on how tensors work internally, you can refer to this blog post: [PyTorch Internals](https://blog.ezyang.com/2019/05/pytorch-internals/).\n",
        "\n",
        "You can inspect a tensor's raw values using the `storage()` function:"
      ],
      "metadata": {
        "id": "DoPV4qbF62uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.shape, t.storage()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdlCbvpuPurj",
        "outputId": "14e3cfdd-77f5-4135-f08a-1f425ef4a62d"
      },
      "execution_count": 548,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([18]),\n",
              "  0\n",
              "  1\n",
              "  2\n",
              "  3\n",
              "  4\n",
              "  5\n",
              "  6\n",
              "  7\n",
              "  8\n",
              "  9\n",
              "  10\n",
              "  11\n",
              "  12\n",
              "  13\n",
              "  14\n",
              "  15\n",
              "  16\n",
              "  17\n",
              " [torch.storage.TypedStorage(dtype=torch.int64, device=cpu) of size 18])"
            ]
          },
          "metadata": {},
          "execution_count": 548
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can apply the reshaping operation again using each of previous strategies and compare their results to ensure they produce equivalent outcomes:"
      ],
      "metadata": {
        "id": "cWxpOLal7XXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([Xemb[:, 0, :], Xemb[:, 1, :], Xemb[:, 2, :]], dim=1) # inefficient\n",
        "t2 = torch.cat(torch.unbind(Xemb, 1), dim=1) # inefficient\n",
        "t3 = Xemb.view(32, 6) # efficient\n",
        "torch.equal(t1, t2), torch.equal(t2, t3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9_YCQIZQKbq",
        "outputId": "6893c514-a3f5-40cc-c785-3c03bd617464"
      },
      "execution_count": 549,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, True)"
            ]
          },
          "metadata": {},
          "execution_count": 549
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One important detail to explore is how to make the reshaping process more flexible. Currently, it's hardcoded for $32$ examples, but we can make it adaptable by softcoding it as follows:"
      ],
      "metadata": {
        "id": "lKVb_zt18DRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xemb.view(Xemb.shape[0], 6)"
      ],
      "metadata": {
        "id": "_cINn9sY8OIT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cc1adae-39d0-4adc-9682-23a6877f325a"
      },
      "execution_count": 550,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00,  1.3398e+00,\n",
              "          9.7887e-01],\n",
              "        [-4.2061e-01, -2.2788e+00,  1.3398e+00,  9.7887e-01, -1.8286e+00,\n",
              "          4.1638e-01],\n",
              "        [ 1.3398e+00,  9.7887e-01, -1.8286e+00,  4.1638e-01, -1.8286e+00,\n",
              "          4.1638e-01],\n",
              "        [-1.8286e+00,  4.1638e-01, -1.8286e+00,  4.1638e-01, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.3372e+00,\n",
              "          1.1549e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -1.3372e+00,  1.1549e+00,  3.1752e+00,\n",
              "         -7.3441e-01],\n",
              "        [-1.3372e+00,  1.1549e+00,  3.1752e+00, -7.3441e-01, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [ 3.1752e+00, -7.3441e-01, -4.8332e-01,  1.0488e+00, -4.8061e-01,\n",
              "         -2.3162e+00],\n",
              "        [-4.8332e-01,  1.0488e+00, -4.8061e-01, -2.3162e+00, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [-4.8061e-01, -2.3162e+00, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -1.4616e-03,  9.9255e-01, -4.8061e-01,\n",
              "         -2.3162e+00],\n",
              "        [-1.4616e-03,  9.9255e-01, -4.8061e-01, -2.3162e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.8332e-01,  1.0488e+00, -9.1898e-01,\n",
              "         -2.4123e+00],\n",
              "        [-4.8332e-01,  1.0488e+00, -9.1898e-01, -2.4123e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-9.1898e-01, -2.4123e+00, -1.4616e-03,  9.9255e-01,  1.8368e+00,\n",
              "         -1.1358e+00],\n",
              "        [-1.4616e-03,  9.9255e-01,  1.8368e+00, -1.1358e+00,  1.3398e+00,\n",
              "          9.7887e-01],\n",
              "        [ 1.8368e+00, -1.1358e+00,  1.3398e+00,  9.7887e-01,  3.1752e+00,\n",
              "         -7.3441e-01],\n",
              "        [ 1.3398e+00,  9.7887e-01,  3.1752e+00, -7.3441e-01,  3.1752e+00,\n",
              "         -7.3441e-01],\n",
              "        [ 3.1752e+00, -7.3441e-01,  3.1752e+00, -7.3441e-01, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -9.1898e-01,\n",
              "         -2.4123e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -9.1898e-01, -2.4123e+00, -1.3372e+00,\n",
              "          1.1549e+00],\n",
              "        [-9.1898e-01, -2.4123e+00, -1.3372e+00,  1.1549e+00,  1.8801e+00,\n",
              "         -4.0999e-01],\n",
              "        [-1.3372e+00,  1.1549e+00,  1.8801e+00, -4.0999e-01, -1.6380e-01,\n",
              "          2.8204e-01],\n",
              "        [ 1.8801e+00, -4.0999e-01, -1.6380e-01,  2.8204e-01, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [-1.6380e-01,  2.8204e-01, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "          9.9255e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 550
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's an even more flexible approach: by setting `-1` in the first dimension, we let PyTorch automatically calculate its size. With $192$ elements and the second dimension fixed at $6$, PyTorch determines the first dimension should be $32$ since $32 \\times 6 = 192$:"
      ],
      "metadata": {
        "id": "veNX1bHh8SxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xemb.view(-1, 6)"
      ],
      "metadata": {
        "id": "V50cgzmc8cCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b7cdcb4-6274-4334-e3e9-18ae367b0df3"
      },
      "execution_count": 551,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00,  1.3398e+00,\n",
              "          9.7887e-01],\n",
              "        [-4.2061e-01, -2.2788e+00,  1.3398e+00,  9.7887e-01, -1.8286e+00,\n",
              "          4.1638e-01],\n",
              "        [ 1.3398e+00,  9.7887e-01, -1.8286e+00,  4.1638e-01, -1.8286e+00,\n",
              "          4.1638e-01],\n",
              "        [-1.8286e+00,  4.1638e-01, -1.8286e+00,  4.1638e-01, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.3372e+00,\n",
              "          1.1549e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -1.3372e+00,  1.1549e+00,  3.1752e+00,\n",
              "         -7.3441e-01],\n",
              "        [-1.3372e+00,  1.1549e+00,  3.1752e+00, -7.3441e-01, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [ 3.1752e+00, -7.3441e-01, -4.8332e-01,  1.0488e+00, -4.8061e-01,\n",
              "         -2.3162e+00],\n",
              "        [-4.8332e-01,  1.0488e+00, -4.8061e-01, -2.3162e+00, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [-4.8061e-01, -2.3162e+00, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -1.4616e-03,  9.9255e-01, -4.8061e-01,\n",
              "         -2.3162e+00],\n",
              "        [-1.4616e-03,  9.9255e-01, -4.8061e-01, -2.3162e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.8332e-01,  1.0488e+00, -9.1898e-01,\n",
              "         -2.4123e+00],\n",
              "        [-4.8332e-01,  1.0488e+00, -9.1898e-01, -2.4123e+00, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-9.1898e-01, -2.4123e+00, -1.4616e-03,  9.9255e-01,  1.8368e+00,\n",
              "         -1.1358e+00],\n",
              "        [-1.4616e-03,  9.9255e-01,  1.8368e+00, -1.1358e+00,  1.3398e+00,\n",
              "          9.7887e-01],\n",
              "        [ 1.8368e+00, -1.1358e+00,  1.3398e+00,  9.7887e-01,  3.1752e+00,\n",
              "         -7.3441e-01],\n",
              "        [ 1.3398e+00,  9.7887e-01,  3.1752e+00, -7.3441e-01,  3.1752e+00,\n",
              "         -7.3441e-01],\n",
              "        [ 3.1752e+00, -7.3441e-01,  3.1752e+00, -7.3441e-01, -1.4616e-03,\n",
              "          9.9255e-01],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -4.2061e-01,\n",
              "         -2.2788e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -4.2061e-01, -2.2788e+00, -9.1898e-01,\n",
              "         -2.4123e+00],\n",
              "        [-4.2061e-01, -2.2788e+00, -9.1898e-01, -2.4123e+00, -1.3372e+00,\n",
              "          1.1549e+00],\n",
              "        [-9.1898e-01, -2.4123e+00, -1.3372e+00,  1.1549e+00,  1.8801e+00,\n",
              "         -4.0999e-01],\n",
              "        [-1.3372e+00,  1.1549e+00,  1.8801e+00, -4.0999e-01, -1.6380e-01,\n",
              "          2.8204e-01],\n",
              "        [ 1.8801e+00, -4.0999e-01, -1.6380e-01,  2.8204e-01, -4.8332e-01,\n",
              "          1.0488e+00],\n",
              "        [-1.6380e-01,  2.8204e-01, -4.8332e-01,  1.0488e+00, -1.4616e-03,\n",
              "          9.9255e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 551
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With that out of the way let's finally run the *forward pass* for the first layer (the hidden layer):"
      ],
      "metadata": {
        "id": "FFBMRyVN767e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = Xemb.view(-1, 6) @ W1 + b1\n",
        "h1.shape, h1"
      ],
      "metadata": {
        "id": "TOG9mfcROEJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29c1f7b2-42ac-4640-f055-d8cb52e50598"
      },
      "execution_count": 552,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 100]),\n",
              " tensor([[-4.5821,  3.3886,  8.3542,  ..., -1.6908, -1.4761, -1.3896],\n",
              "         [-0.7359,  4.3256,  5.5844,  ..., -2.0712,  0.9985,  4.1693],\n",
              "         [-4.4854,  6.9301, -1.6082,  ..., -3.2926,  2.7513, -1.7095],\n",
              "         ...,\n",
              "         [ 3.8118,  2.8222,  3.9976,  ..., -2.6320,  5.2659,  0.6684],\n",
              "         [-2.5701,  0.3696, -3.8014,  ...,  3.0659, -0.4773, -2.0006],\n",
              "         [-1.1837,  0.4894, -4.5214,  ..., -2.8452,  0.2084, -0.0983]]))"
            ]
          },
          "metadata": {},
          "execution_count": 552
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're still missing a non-linear function to squash the layer's activation, let's use `tanh`:"
      ],
      "metadata": {
        "id": "6tluD2mP8jDF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "h1 = torch.tanh(Xemb.view(-1, 6) @ W1 + b1)\n",
        "h1.shape, h1"
      ],
      "metadata": {
        "id": "3EqJAcDkQ06I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cbe040b-a5ca-4812-8326-6de1d6bd12b7"
      },
      "execution_count": 553,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 100]),\n",
              " tensor([[-0.9998,  0.9977,  1.0000,  ..., -0.9342, -0.9007, -0.8831],\n",
              "         [-0.6267,  0.9997,  1.0000,  ..., -0.9687,  0.7610,  0.9995],\n",
              "         [-0.9997,  1.0000, -0.9229,  ..., -0.9972,  0.9919, -0.9366],\n",
              "         ...,\n",
              "         [ 0.9990,  0.9930,  0.9993,  ..., -0.9897,  0.9999,  0.5839],\n",
              "         [-0.9884,  0.3536, -0.9990,  ...,  0.9957, -0.4440, -0.9641],\n",
              "         [-0.8286,  0.4537, -0.9998,  ..., -0.9933,  0.2054, -0.0980]]))"
            ]
          },
          "metadata": {},
          "execution_count": 553
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll create the second and final layer, the *output layer*.\n",
        "\n",
        "Since the previous layer has $100$ neurons, it outputs $100$ values, meaning the *output layer* will have $100$ inputs. To output probabilities for each of the $27$ possible characters, it will need $27$ neurons. Therefore, the weight matrix `W2` for the *output layer* will have a shape of $(100, 27)$, representing $100 \\times 27 = 2700$ weights.\n",
        "\n",
        "We'll also create a tensor `b2` of shape $(27)$ for the bias values of the output neurons:"
      ],
      "metadata": {
        "id": "OlgKynA48ttu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W2 = torch.randn((100, 27)) # Create output layer (receives 100 inputs from previous layer, and outputs 27 for the possible next character)\n",
        "b2 = torch.randn(27) # Add a bias to each of the possible outputs"
      ],
      "metadata": {
        "id": "djpN6BvwQ5F7"
      },
      "execution_count": 554,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now continue the *forward pass* through the *output layer* to get the logits:"
      ],
      "metadata": {
        "id": "SP_FzCzY9X92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits = h1 @ W2 + b2\n",
        "logits.shape"
      ],
      "metadata": {
        "id": "kta2nfO0RHi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95bf270-e229-445a-a70e-0e662a8b0dec"
      },
      "execution_count": 555,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 27])"
            ]
          },
          "metadata": {},
          "execution_count": 555
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `logits` tensor has a shape of $(32, 27)$ because it represents the unnormalized scores (raw predictions) for each possible next character across the $32$ input character sequences fed into the network.\n",
        "\n",
        "Let's inspect the `logits` tensor:"
      ],
      "metadata": {
        "id": "QffRdNIv9leL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits.shape, logits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adm4fYKO90eZ",
        "outputId": "3b3677c0-a321-4119-d333-1bb914f315cc"
      },
      "execution_count": 556,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]),\n",
              " tensor([-17.1940,   3.4736, -13.7481,  18.1992, -12.1185,  18.9400, -11.9435,\n",
              "          -2.7839, -12.4418, -20.0452,  22.3156,  -6.9423, -15.3579,   3.3752,\n",
              "         -11.5236,   9.5172,  -7.9597,  -7.7149,   8.2347,  -8.1456,  -7.4891,\n",
              "          -2.1093,   8.4081,   4.7288,  -9.2167,  10.6841,   1.7673]))"
            ]
          },
          "metadata": {},
          "execution_count": 556
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To convert the negative numbers into positive ones and prepare the logits for normalization into a probability distribution, we can exponentiate the logits. This will turn them positive (a requirement for normalization), while amplifying the differences between higher and lower values (for faster training):"
      ],
      "metadata": {
        "id": "Ja_Zhk8R91-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "counts = logits.exp()\n",
        "counts.shape, counts[0]"
      ],
      "metadata": {
        "id": "K-HXPwX2RLlZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fcaabd2-e3c4-476e-f5d7-5ec72fed6e31"
      },
      "execution_count": 557,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]),\n",
              " tensor([3.4097e-08, 3.2254e+01, 1.0697e-06, 8.0129e+07, 5.4574e-06, 1.6808e+08,\n",
              "         6.5012e-06, 6.1799e-02, 3.9500e-06, 1.9701e-09, 4.9153e+09, 9.6609e-04,\n",
              "         2.1387e-07, 2.9231e+01, 9.8940e-06, 1.3591e+04, 3.4927e-04, 4.4612e-04,\n",
              "         3.7696e+03, 2.9000e-04, 5.5917e-04, 1.2133e-01, 4.4832e+03, 1.1316e+02,\n",
              "         9.9361e-05, 4.3658e+04, 5.8551e+00]))"
            ]
          },
          "metadata": {},
          "execution_count": 557
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now normalize the logits to obtain a probability distribution:"
      ],
      "metadata": {
        "id": "PG_e9vYl-Gs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs = counts / counts.sum(1, keepdims=True)\n",
        "probs.shape, probs[0].sum(), probs[0]"
      ],
      "metadata": {
        "id": "9UHh59ehRPAo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2991034d-cda2-4e28-fa25-76bb988a5fa4"
      },
      "execution_count": 558,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 27]),\n",
              " tensor(1.0000),\n",
              " tensor([6.6035e-18, 6.2464e-09, 2.0717e-16, 1.5518e-02, 1.0569e-15, 3.2552e-02,\n",
              "         1.2591e-15, 1.1968e-11, 7.6498e-16, 3.8153e-19, 9.5192e-01, 1.8710e-13,\n",
              "         4.1419e-17, 5.6610e-09, 1.9161e-15, 2.6322e-06, 6.7642e-14, 8.6398e-14,\n",
              "         7.3004e-07, 5.6162e-14, 1.0829e-13, 2.3497e-11, 8.6825e-07, 2.1915e-08,\n",
              "         1.9243e-14, 8.4551e-06, 1.1339e-09]))"
            ]
          },
          "metadata": {},
          "execution_count": 558
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using PyTorch's advanced indexing, we can retrieve the probability assigned by the model to the correct next character (found in $Y$) for each of the $32$ inputs:"
      ],
      "metadata": {
        "id": "HYqROZeT-OFo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "probs[torch.arange(32), Y] # Probability for each of the possible examples being the expected character"
      ],
      "metadata": {
        "id": "GxufUL3hRz--",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ec06f5-5eee-43cd-8051-60ed10b81428"
      },
      "execution_count": 559,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3.2552e-02, 2.4674e-05, 1.4123e-07, 8.0032e-12, 2.8475e-10, 2.6322e-06,\n",
              "        2.2335e-11, 1.8446e-12, 2.4507e-07, 5.7547e-16, 6.6817e-15, 3.4337e-07,\n",
              "        6.2464e-09, 9.4887e-01, 1.3744e-09, 3.9650e-09, 3.8153e-19, 6.2392e-06,\n",
              "        7.5112e-09, 4.7126e-14, 9.2577e-06, 3.7270e-03, 1.6060e-07, 5.2157e-12,\n",
              "        2.1482e-04, 5.6162e-14, 6.8547e-06, 8.5558e-11, 1.4128e-10, 1.6863e-06,\n",
              "        2.6734e-11, 4.4876e-08])"
            ]
          },
          "metadata": {},
          "execution_count": 559
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now calculate the *negative log likelihood* and use it as our loss function:"
      ],
      "metadata": {
        "id": "PPaQEWie-l_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nll_loss = -probs[torch.arange(32), Y].log().mean()\n",
        "nll_loss"
      ],
      "metadata": {
        "id": "2PWs633eSJ2j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89333354-5fd2-44fc-dda0-305933103654"
      },
      "execution_count": 560,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(19.1288)"
            ]
          },
          "metadata": {},
          "execution_count": 560
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improve Numerical Stability ‚öñÔ∏è\n",
        "\n",
        "Let's discuss the benefits of using `F.cross_entropy()` from PyTorch instead of manually calculating the *negative log likelihood*.\n",
        "\n",
        "First, let's define a `build_model()` function that allows us to recreate our model whenever needed with the same initial parameters when needed:"
      ],
      "metadata": {
        "id": "R2qse8k3_gFZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42 # Default seed to initialize random number generators with, for reproducibility\n",
        "\n",
        "def build_model(seed=SEED):\n",
        "  generator = torch.Generator().manual_seed(seed) # Use a generator so that we always get the same model with the same parameters\n",
        "  C = torch.randn((27, 2), generator=generator)\n",
        "  W1 = torch.randn((6, 100), generator=generator)\n",
        "  b1 = torch.randn(100, generator=generator)\n",
        "  W2 = torch.randn((100, 27), generator=generator)\n",
        "  b2 = torch.randn(27, generator=generator)\n",
        "  parameters = [C, W1, b1, W2, b2]\n",
        "  for p in parameters: p.requires_grad = True # Enable gradient tracking\n",
        "  return parameters\n",
        "\n",
        "model = build_model() # Create the model\n",
        "C, W1, b1, W2, b2 = model # Unpack the model parameters\n",
        "\n",
        "# Count the number of parameters\n",
        "num_parameters = sum(p.nelement() for p in model)\n",
        "print(f\"Number of parameters: {num_parameters}\")"
      ],
      "metadata": {
        "id": "Qt3JdUhdSaDJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86277a52-b4a7-409e-a216-c1c81892c493"
      },
      "execution_count": 561,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of parameters: 3481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's encapsulate the forward pass into a `forward()` method:"
      ],
      "metadata": {
        "id": "Xu_9XtjWAayp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def forward(dataset, model, loss_fn=\"F.cross_entropy\"):\n",
        "  X, Y = dataset # Unpack the dataset\n",
        "  C, W1, b1, W2, b2 = model # Unpack the model parameters\n",
        "\n",
        "  Xemb = C[X] # Embed X tensor (replaces character integer encoding with embeddings)\n",
        "  h = torch.tanh(Xemb.view(-1, 6) @ W1 + b1) # Activate hidden layer, resulting in (32, 100)\n",
        "  logits = h @ W2 + b2 # Activate output layer, resulting in (32, 27)\n",
        "\n",
        "  # Run efficient pytorch cross-entropy loss function by default\n",
        "  if loss_fn == \"F.cross_entropy\":\n",
        "    loss = F.cross_entropy(logits, Y)\n",
        "  # Otherwise calculate same loss function manually\n",
        "  else:\n",
        "    counts = logits.exp()\n",
        "    probs = counts / counts.sum(1, keepdims=True)\n",
        "    loss = -probs[torch.arange(Xemb.shape[0]), Y].log().mean()\n",
        "\n",
        "  return loss, logits"
      ],
      "metadata": {
        "id": "lvwPPu15AXB5"
      },
      "execution_count": 562,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we run the *forward pass* with our manual loss calculation:"
      ],
      "metadata": {
        "id": "gc32VjTnGf5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = (X, Y)\n",
        "loss, _ = forward(dataset, model, loss_fn=\"manual\")\n",
        "loss"
      ],
      "metadata": {
        "id": "gpRE7GEDSzQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91fae4b1-1071-4901-d59a-9772a9870983"
      },
      "execution_count": 563,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.7758, grad_fn=<NegBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 563
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And now we use PyTorch's `F.cross_entropy` loss function:"
      ],
      "metadata": {
        "id": "Qzejubc2GjP4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, _ = forward(dataset, model, loss_fn=\"F.cross_entropy\")\n",
        "loss"
      ],
      "metadata": {
        "id": "FxufdWcZS1-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ae7cb4-3f84-426f-fef0-43d835e63965"
      },
      "execution_count": 564,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(17.7758, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 564
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We were fortunate to achieve the same loss with both approaches, but this might not always be the case. Let's explore an edge case where certain logits can cause numerical instability in our manual loss calculation.\n",
        "\n",
        "First, consider a stable example:"
      ],
      "metadata": {
        "id": "CCa0hWDZBAIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define temporary function to manually\n",
        "# calculate probabilities for testing purposes\n",
        "def _calc_probs(logits):\n",
        "  counts = logits.exp()\n",
        "  probs = counts / counts.sum()\n",
        "  return {\n",
        "      \"counts\" : counts,\n",
        "      \"probs\" : probs\n",
        "  }\n",
        "\n",
        "_calc_probs(torch.tensor([-2.0, -3.0, 0.0, -5.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQsn9EYsAJtD",
        "outputId": "0881ce77-93cb-4a38-87a7-a8d5511b52e7"
      },
      "execution_count": 565,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'counts': tensor([0.1353, 0.0498, 1.0000, 0.0067]),\n",
              " 'probs': tensor([0.1135, 0.0418, 0.8390, 0.0057])}"
            ]
          },
          "metadata": {},
          "execution_count": 565
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Everything was fine with the previous calculation, and everything should still be fine if we had big negative logits:"
      ],
      "metadata": {
        "id": "sGYypgOFBPwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_calc_probs(torch.tensor([-100.0, -3.0, 0.0, 5.0]))"
      ],
      "metadata": {
        "id": "GRa7AQgRT5Wn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a167a8a-6890-4c3a-cb58-0ea15ba1404a"
      },
      "execution_count": 566,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'counts': tensor([3.7835e-44, 4.9787e-02, 1.0000e+00, 1.4841e+02]),\n",
              " 'probs': tensor([0.0000e+00, 3.3311e-04, 6.6906e-03, 9.9298e-01])}"
            ]
          },
          "metadata": {},
          "execution_count": 566
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "But if we had big positive logits we would not be so lucky:"
      ],
      "metadata": {
        "id": "Vre8_rxRBV-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_calc_probs(torch.tensor([-100.0, -3.0, 0.0, 100.0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGbHhYFlAdog",
        "outputId": "7aa8d5ca-3c79-4a31-ba37-ff8ee4538575"
      },
      "execution_count": 567,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'counts': tensor([3.7835e-44, 4.9787e-02, 1.0000e+00,        inf]),\n",
              " 'probs': tensor([0., 0., 0., nan])}"
            ]
          },
          "metadata": {},
          "execution_count": 567
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observed that the `counts` tensor contains a positive infinity, and the `probs` tensor has a `NaN` value. This issue arises because the exponentiation of large numbers can lead to extremely large values, which may exceed the representable range of the data types, resulting in overflow.\n",
        "\n",
        "To illustrate this, let's plot the `exp()` function over the range $[-100, 100]$. This will help us visualize how exponentiating large numbers can lead to such overflow issues:"
      ],
      "metadata": {
        "id": "9SjgXwvIBmrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "px = torch.linspace(-100, 100, 400) # Plot 400 points in range [-100, 100]\n",
        "py = torch.exp(px) # Calculate exp() for each x value\n",
        "plt.plot(px, py) # Plot the values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "NYRWhOmuISRn",
        "outputId": "b5e4c51c-2035-4da6-96ae-36aed5883952"
      },
      "execution_count": 568,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ae19194a6e0>]"
            ]
          },
          "metadata": {},
          "execution_count": 568
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGsCAYAAAAPJKchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAq+UlEQVR4nO3de3TU9Z3/8dckJBNSkgBCLmC4iaIIBUQICcrlt5GUUtps++NwqGvwAhy60FVh1aZWWelCXC3Kr10EPQo5rbKwVgUPsHRDbKBKrOWSKgq0USRckqC7koEAucx8fn/gTJhCIJNJ8pnJPB/nzMH5zvc73/e3X0Je/dy+DmOMEQAAgCVRtgsAAACRjTACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArAqrMLJr1y5Nnz5dffr0kcPh0KZNmwI6/vDhw5o8ebJSUlIUFxenQYMG6Wc/+5kaGhr89lu5cqWGDBmirl27Kj09XQ8//LAuXLjQhlcCAAC8utguIBC1tbUaMWKE7r//fn3/+98P+PiYmBjl5eXptttuU/fu3fXnP/9Zc+fOlcfj0fLlyyVJ69ev109+8hOtXbtWWVlZ+stf/qJ7771XDodDzz33XFtfEgAAES+swsjUqVM1derUZj+vq6vT448/rv/4j//Q6dOnNWzYMP3bv/2bJk2aJEkaNGiQBg0a5Nu/f//+Kikp0R/+8Afftt27d2v8+PH64Q9/KEkaMGCAZs2apT/+8Y/tc1EAAES4sOqmuZaFCxeqtLRUGzZs0IcffqgZM2boW9/6lv76179ecf/y8nJt375dEydO9G3LysrS3r179cEHH0iSPvvsM23btk3f/va3O+QaAACINA5jjLFdRGs4HA699dZbys3NlSRVVFRo0KBBqqioUJ8+fXz7ZWdna+zYsb5uGOli4Ni3b5/q6uo0b948rV69WlFRTbnsl7/8pf75n/9Zxhg1NjZq/vz5Wr16dYddGwAAkaTTtIx89NFHcrvduummm9StWzffa+fOnfr000/99t24caP27dun9evXa+vWrfrFL37h+6ykpETLly/XCy+8oH379unNN9/U1q1b9fOf/7yjLwkAgIgQVmNGrubs2bOKjo7W3r17FR0d7fdZt27d/N6np6dLkoYOHSq326158+Zp8eLFio6O1hNPPKF77rlHc+bMkSQNHz5ctbW1mjdvnh5//HG/FhQAABC8ThNGRo0aJbfbrVOnTunOO+9s8XEej0cNDQ3yeDyKjo7WuXPnLgsc3nATpj1aAACEtLAKI2fPnlV5ebnv/ZEjR1RWVqaePXvqpptu0t133628vDytWLFCo0aN0hdffKHi4mJ985vf1LRp0/Taa68pJiZGw4cPl9Pp1J49e5Sfn6+ZM2cqJiZGkjR9+nQ999xzGjVqlDIyMlReXq4nnnhC06dPv6zFBQAABC+sBrCWlJRo8uTJl22fPXu2CgsL1dDQoH/913/Vr3/9a504cUK9evXSuHHj9NRTT2n48OHauHGjnnnmGf3lL3+RMUb9+/fXP/zDP+jhhx9WXFycJKmxsVHLli3Tb37zG504cUK9e/fW9OnTtWzZMnXv3r2DrxgAgM4vrMIIAADofBiNCQAArCKMAAAAq8JiAKvH49HJkyeVkJAgh8NhuxwAANACxhidOXNGffr0uerSGGERRk6ePOlbGwQAAISXY8eO6frrr2/287AIIwkJCZIuXkxiYqLlagAAQEu4XC6lp6f7fo83JyzCiLdrJjExkTACAECYudYQCwawAgAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArAqLB+UBAID28f92/FWnz9fr/vEDld4z3koNtIwAABDBfrvvmNa997m+PFtnrQbCCAAAEczjufhnlMNhrQbCCAAAEcxjjCTCCAAAsMQXRiwmAsIIAAARzHMxi9AyAgAA7PB46KYBAAAWebtpoummAQAANni7aRy0jAAAABvopgEAAFb5umkIIwAAwIambhp7NRBGAACIYG7fOiO0jAAAAAsM3TQAAMCmpkXP7NVAGAEAIIK5v04jYTO1t6CgQGPGjFFCQoKSk5OVm5urw4cPX/WYwsJCORwOv1dcXFxQRQMAgOB5u2gkKTpcxozs3LlTCxYs0Pvvv6+ioiI1NDRoypQpqq2tvepxiYmJqqys9L2OHj0aVNEAACB4nqYsYrWbpksgO2/fvt3vfWFhoZKTk7V3715NmDCh2eMcDodSU1NbVyEAAGgXnktaRsKmm+Zv1dTUSJJ69ux51f3Onj2r/v37Kz09Xd/73vf08ccfX3X/uro6uVwuvxcAAGhb7kuaRsJyAKvH49FDDz2k8ePHa9iwYc3uN2TIEK1du1abN2/Wq6++Ko/Ho6ysLB0/frzZYwoKCpSUlOR7paent7ZMAADQjEsaRqyOGXGYS0evBOBHP/qR/uu//kvvvvuurr/++hYf19DQoFtuuUWzZs3Sz3/+8yvuU1dXp7q6Ot97l8ul9PR01dTUKDExsTXlAgCAv1Fb16hbl/xOknTo599SXEx0m36/y+VSUlLSNX9/BzRmxGvhwoXasmWLdu3aFVAQkaSYmBiNGjVK5eXlze7jdDrldDpbUxoAAGght9+YEXt1BNRNY4zRwoUL9dZbb+mdd97RwIEDAz6h2+3WRx99pLS0tICPBQAAbcd4mv7b5gqsAbWMLFiwQOvXr9fmzZuVkJCgqqoqSVJSUpK6du0qScrLy1Pfvn1VUFAgSVq6dKnGjRunwYMH6/Tp03r22Wd19OhRzZkzp40vBQAABOLS2TRR4RJGVq9eLUmaNGmS3/Z169bp3nvvlSRVVFQoKqqpweWrr77S3LlzVVVVpR49emj06NHavXu3hg4dGlzlAAAgKKHSTdPqAawdqaUDYAAAQMudOnNBY5cVK8ohfVYwrc2/v6W/v3k2DQAAEcr4HpJnsVlEhBEAACKWd9EzwggAALDCO4A1ynIaIIwAABCh6KYBAABW0U0DAACs8nXT2M0ihBEAACKV96G9UZbTCGEEAIAI1dQyQhgBAAAW0E0DAACs8nz9oDxaRgAAgBV00wAAAKvopgEAAFYxmwYAAFhFNw0AALDK46GbBgAAWEQ3DQAAsIpuGgAAYBXdNAAAwCpfNw0tIwAAwAa6aQAAgFVubxixnAYIIwAARCjzdRiJpmUEAADY4H1QnoMwAgAAbHDzbBoAAGCTr5uGRc8AAIAN3qm9dNMAAAAr3Cx6BgAAbGKdEQAAYNXXWYQxIwAAwA5vywhjRgAAgBWMGQEAAFb5umloGQEAADbQTQMAAKxiBVYAAGCVh9k0AADAJsM6IwAAwCbvbBrLWYQwAgBApKKbBgAAWEU3DQAAsIpuGgAAYJWHRc8AAIBNPLUXAABY5fE+m8ZyGiCMAAAQobzdNCwHDwAArPB20zBmBAAAWGF4Ng0AALDJzVN7AQCATazACgAArPLQTQMAAGzyTe2lmwYAANjg7aaJopsGAADYEJbdNAUFBRozZowSEhKUnJys3NxcHT58+JrHvf7667r55psVFxen4cOHa9u2ba0uGAAAtI2w7KbZuXOnFixYoPfff19FRUVqaGjQlClTVFtb2+wxu3fv1qxZs/TAAw9o//79ys3NVW5urg4cOBB08QAAoPV83TSWw4jDeFc8aYUvvvhCycnJ2rlzpyZMmHDFfWbOnKna2lpt2bLFt23cuHEaOXKk1qxZ06LzuFwuJSUlqaamRomJia0tFwAAXOLxtz7Sa3+s0MPZN+nB7Bvb/Ptb+vs7qDEjNTU1kqSePXs2u09paamys7P9tuXk5Ki0tLTZY+rq6uRyufxeAACgbYXlmJFLeTwePfTQQxo/fryGDRvW7H5VVVVKSUnx25aSkqKqqqpmjykoKFBSUpLvlZ6e3toyAQBAMzyei3+G7WyaBQsW6MCBA9qwYUNb1iNJys/PV01Nje917NixNj8HAACRrqllxG4Y6dKagxYuXKgtW7Zo165duv7666+6b2pqqqqrq/22VVdXKzU1tdljnE6nnE5na0oDAAAt5A7HbhpjjBYuXKi33npL77zzjgYOHHjNYzIzM1VcXOy3raioSJmZmYFVCgAA2pQJkWfTBNQysmDBAq1fv16bN29WQkKCb9xHUlKSunbtKknKy8tT3759VVBQIEl68MEHNXHiRK1YsULTpk3Thg0btGfPHr300kttfCkAACAQnnB8au/q1atVU1OjSZMmKS0tzffauHGjb5+KigpVVlb63mdlZWn9+vV66aWXNGLECP32t7/Vpk2brjroFQAAtD+3JzS6aQJqGWnJkiQlJSWXbZsxY4ZmzJgRyKkAAEA7MyGy6BnPpgEAIEL5ZtOE69ReAAAQ3sJ+0TMAABDe3N5Fz+imAQAANnjHgkYTRgAAgA1NU3vt1kEYAQAgQrmZTQMAAGzyddMwmwYAANhANw0AALCqaQVWWkYAAIAFnhB5UB5hBACACGVY9AwAANjk7aYJq6f2AgCAzsPXTUMYAQAANvi6aSynAcIIAAARym3opgEAABZ5eFAeAACwycOD8gAAgE3G92wau3UQRgAAiFCMGQEAAFZ5eFAeAACwiW4aAABgFSuwAgAAq+imAQAAVtFNAwAArPJ207DoGQAAsMLbTUMYAQAAVnif2suD8gAAgBW0jAAAAKsIIwAAwCqPbwCr3ToIIwAARCjfmBFaRgAAgA0segYAAKzy+J7aa7cOwggAABHK47n4J900AADACmbTAAAAq3xhhEXPAACADcymAQAA1njXGJEIIwAAwAJvF40kRRNGAABAR7ukYUQOxowAAICOdmnLCN00AACgw9FNAwAArPLrpmEFVgAA0NHczKYBAAA2XTq1twsPygMAAB2t8dKWEcIIAADoaN4BrLZbRSTCCAAAEcnbMhJNGAEAADa43bSMAAAAixo9Hkm0jAAAAEvcdNMAAACbmsaM2I8C9isAAAAdztsyEpZjRnbt2qXp06erT58+cjgc2rRp01X3LykpkcPhuOxVVVXV2poBAECQwrqbpra2ViNGjNCqVasCOu7w4cOqrKz0vZKTkwM9NQAAaCPebpou0fbDSJdAD5g6daqmTp0a8ImSk5PVvXv3gI8DAABtL6xbRlpr5MiRSktL01133aX33nvvqvvW1dXJ5XL5vQAAQNvxTe21/chedUAYSUtL05o1a/TGG2/ojTfeUHp6uiZNmqR9+/Y1e0xBQYGSkpJ8r/T09PYuEwCAiBJKLSMBd9MEasiQIRoyZIjvfVZWlj799FM9//zz+s1vfnPFY/Lz87Vo0SLfe5fLRSABAKANucN5zEhbGDt2rN59991mP3c6nXI6nR1YEQAAkcUd6euMlJWVKS0tzcapAQCALplNE47dNGfPnlV5ebnv/ZEjR1RWVqaePXuqX79+ys/P14kTJ/TrX/9akrRy5UoNHDhQt956qy5cuKCXX35Z77zzjv77v/+77a4CAAAEJKzHjOzZs0eTJ0/2vfeO7Zg9e7YKCwtVWVmpiooK3+f19fVavHixTpw4ofj4eH3zm9/Ujh07/L4DAAB0LN9y8CEwm8ZhjDG2i7gWl8ulpKQk1dTUKDEx0XY5AACEvU37T+ihjWW688Ze+s0DGe1yjpb+/rY/agUAAHS4xhDqpiGMAAAQgdxfL3oWCgNYCSMAAEQgWkYAAIBVvkXPInWdEQAAYFej+2IYiaJlBAAA2OAxobPoGWEEAIAIxJgRAABglTuEloMnjAAAEIG8Y0ZoGQEAAFZ41xkhjAAAACsYMwIAAKxyM5sGAADY5PaNGbEfBexXAAAAOlwjs2kAAIBNbsaMAAAAmxjACgAArGJqLwAAsMp9MYswZgQAANhBywgAALCK2TQAAMAq32yaaPtRwH4FAACgw/lm0zhoGQEAABZ46KYBAAA2sc4IAACwyjtmpEs0YQQAAFjQyNReAABgk5sBrAAAwCbGjAAAAKs8jBkBAAA2NbWM2I8C9isAAAAdzs06IwAAwCbGjAAAAKvchBEAAGAT64wAAACrvs4ijBkBAAB20DICAACsappNYz8K2K8AAAB0OGbTAAAAq9xuwggAALCokUXPAACATW5DywgAALCI5eABAIA1xhhWYAUAAPZ4g4jE1F4AAGBB4yVhJASyCGEEAIBI4zG0jAAAAIsubRlhzAgAAOhw3gXPJGbTAAAAC7wtIw6HFEUYAQAAHc03rddhP4hIhBEAACJOo8cjKTTGi0iEEQAAIs7XWSQkxotIrQgju3bt0vTp09WnTx85HA5t2rTpmseUlJTotttuk9Pp1ODBg1VYWNiKUgEAQFsI+5aR2tpajRgxQqtWrWrR/keOHNG0adM0efJklZWV6aGHHtKcOXP0u9/9LuBiAQBA8HzPpYkOjQ6SLoEeMHXqVE2dOrXF+69Zs0YDBw7UihUrJEm33HKL3n33XT3//PPKyckJ9PQAACBIjSH0XBqpA8aMlJaWKjs7229bTk6OSktLmz2mrq5OLpfL7wUAANpGxM2mqaqqUkpKit+2lJQUuVwunT9//orHFBQUKCkpyfdKT09v7zIBAIgYEdcy0hr5+fmqqanxvY4dO2a7JAAAOo2mMSOhEUYCHjMSqNTUVFVXV/ttq66uVmJiorp27XrFY5xOp5xOZ3uXBgBARHJHWstIZmamiouL/bYVFRUpMzOzvU8NAACuwDu1N2zXGTl79qzKyspUVlYm6eLU3bKyMlVUVEi62MWSl5fn23/+/Pn67LPP9Oijj+rQoUN64YUX9J//+Z96+OGH2+YKAABAQBrd3paR0BitEXAVe/bs0ahRozRq1ChJ0qJFizRq1Cg9+eSTkqTKykpfMJGkgQMHauvWrSoqKtKIESO0YsUKvfzyy0zrBQDAkgb3xZaR2C6hEUYCHjMyadIkGWOa/fxKq6tOmjRJ+/fvD/RUAACgHfjCSIgMYA2NSAQAADpMXePFMBITIiuwhkYVAACgwzR8PWaEMAIAAKwItTEjoVEFAADoMPWN3jEjoREDQqMKAADQYbwtIzEMYAUAADbU000DAABsqmc2DQAAsKmpmyY0YkBoVAEAADqMd2qvk24aAABgA900AADAqnq6aQAAgE0NjcymAQAAFtWzzggAALCJ5eABAIBV9Y0XZ9OwHDwAALCCAawAAMAq7wDWGLppAACADb4xI7SMAAAAG5oGsDKbBgAAWFDHCqwAAMAmHpQHAACs8j4oj3VGAACAFd4H5TGAFQAAWEE3DQAAsKqe5eABAIBN9Y08KA8AAFjEomcAAMAat8fIc3EyDd00AACg43m7aCQGsAIAAAu8g1clwggAALCgwS+MMIAVAAB0sEsXPHM4CCMAAKCDNS14FhpBRCKMAAAQURpCbMEziTACAEBEqWsMraXgJcIIAAARxfvEXsIIAACwgm4aAABg1aWzaUJF6FQCAADanXfRs5guzKYBAAAWNDCAFQAA2OQdwEo3DQAAsKLe7ZbEAFYAAGBJQyNTewEAgEXeAax00wAAACu8U3tj6KYBAAA28KA8AABg1fmGiwNY42KiLVfShDACAEAE8YaReMIIAACw4UL9xTDSNZYwAgAALDhHGAEAADZ5u2m60k0DAABsOF9PGAEAABb5WkbCvZtm1apVGjBggOLi4pSRkaEPPvig2X0LCwvlcDj8XnFxca0uGAAAtN65ztAysnHjRi1atEhLlizRvn37NGLECOXk5OjUqVPNHpOYmKjKykrf6+jRo0EVDQAAWueCd2pvbBfLlTQJOIw899xzmjt3ru677z4NHTpUa9asUXx8vNauXdvsMQ6HQ6mpqb5XSkpKUEUDAIDWaeqmCZ2RGgFVUl9fr7179yo7O7vpC6KilJ2drdLS0maPO3v2rPr376/09HR973vf08cff3zV89TV1cnlcvm9AABA8Jq6acK0ZeTLL7+U2+2+rGUjJSVFVVVVVzxmyJAhWrt2rTZv3qxXX31VHo9HWVlZOn78eLPnKSgoUFJSku+Vnp4eSJkAAKAZEbnoWWZmpvLy8jRy5EhNnDhRb775pnr37q0XX3yx2WPy8/NVU1Pjex07dqy9ywQAoNMzxuhcCK4zElAbTa9evRQdHa3q6mq/7dXV1UpNTW3Rd8TExGjUqFEqLy9vdh+n0ymn0xlIaQAA4Boa3EZuj5EUxi0jsbGxGj16tIqLi33bPB6PiouLlZmZ2aLvcLvd+uijj5SWlhZYpQAAICjeBc+kMG4ZkaRFixZp9uzZuv322zV27FitXLlStbW1uu+++yRJeXl56tu3rwoKCiRJS5cu1bhx4zR48GCdPn1azz77rI4ePao5c+a07ZUAAICr8s6k6RLlUGyX0JlNE3AYmTlzpr744gs9+eSTqqqq0siRI7V9+3bfoNaKigpFRTVd4FdffaW5c+eqqqpKPXr00OjRo7V7924NHTq07a4CAABcUyg+l0aSHMYYY7uIa3G5XEpKSlJNTY0SExNtlwMAQFj6+GSNpv3yXfVOcOpPj2df+4AgtfT3d+i00QAAgHbVtPpqaLWMEEYAAIgQofhcGokwAgBAxDgfggueSYQRAAAiRqgOYCWMAAAQIbwtI4wZAQAAVnhbRuJoGQEAADYwgBUAAFjF1F4AAGCVt2UkjjACAABs8I4ZiY8J+Gkw7YowAgBAhGhaZyS0fv2HVjUAAKDdnK1rlCTFx9IyAgAALKg53yBJSuoaY7kSf4QRAAAihIswAgAAbKJlBAAAWOUNI93jCSMAAKCD1Td6fOuM0DICAAA6nLdVRJIS4ggjAACgg3nDSEJcF0VHOSxX448wAgBABAjV8SISYQQAgIgQqtN6JcIIAAARIVSn9UqEEQAAIsLpc/WSCCMAAMCSmvMXn0uT1DXWciWXI4wAABAB6KYBAABWEUYAAIBVhBEAAGBVzfmLA1hZZwQAAFhBywgAALDqy7MXW0Z6xDObBgAAdLALDW79b+3FMNKne5zlai5HGAEAoJOrqrkgSeoaE003DQAA6HiVX4eRtKQ4ORyh9cReiTACAECnV1lzXpKUFoJdNBJhBACATs/bMpKa2NVyJVdGGAEAoJPzjhkJxcGrEmEEAIBOz9tNk5pEGAEAABZcOoA1FBFGAADo5JrCCGNGAABAB7t0wTNaRgAAQIcrP3VW0sUH5IXigmcSYQQAgE7tk0qXJOmW1MSQXPBMIowAANCpHfSGkbREy5U0jzACAEAn1hRGEixX0jzCCAAAnZQxRoeqzkiiZQQAAFhQ5bqg0+caFB3l0ODkbrbLaRZhBACATmrf0dOSpBuTuykuJtpuMVdBGAEAoJMqPlgtSZpwU2/LlVwdYQQAgE6o0e3RO4dPSZKyb0mxXM3VEUYAAOiE9lWc1ulzDeoeH6Pb+nW3Xc5VEUYAAOiE1v/xqCTp/wxJVpfo0P51H9rVAQCAgJWfOqu3/3xSknT/HQMtV3NtrQojq1at0oABAxQXF6eMjAx98MEHV93/9ddf180336y4uDgNHz5c27Zta1WxAADg6hrdHv3L2x/LYy6OFRnWN8l2SdcUcBjZuHGjFi1apCVLlmjfvn0aMWKEcnJydOrUqSvuv3v3bs2aNUsPPPCA9u/fr9zcXOXm5urAgQNBFw8AAJrUN3r0s00H9G75l+oaE61HvzXEdkkt4jDGmEAOyMjI0JgxY/Tv//7vkiSPx6P09HT9+Mc/1k9+8pPL9p85c6Zqa2u1ZcsW37Zx48Zp5MiRWrNmTYvO6XK5lJSUpJqaGiUmhu4KcgAA2PDl2Tr9/tApvfyHIzpcfXHF1Rfuvk3fHp5mta6W/v7uEsiX1tfXa+/evcrPz/dti4qKUnZ2tkpLS694TGlpqRYtWuS3LScnR5s2bWr2PHV1daqrq/O9d7lcgZTZYq+8e0TH/vdcu3z31QSY/5qOC+qcQRwbxJmDO28QxwZzsK3r5R618Jx2Cg7uWoO4P0GdN4hjgzqvnesN7v6G18+9kdG5ere+OlevaledvjjT9Duze3yMnv2/I3TX0NCeznupgMLIl19+KbfbrZQU/wtMSUnRoUOHrnhMVVXVFfevqqpq9jwFBQV66qmnAimtVbZ+eFL7Kk63+3kAAGhvN6cm6DvfTNPdGf3V4xuxtssJSEBhpKPk5+f7taa4XC6lp6e3+Xl+MPp6Zd3Qq9XHOxzBnT+ow4M8eTBHB3NqR3BXHeS5gxPUuYP9yxKE4P+etv4LbP6MhPN1ByOYv2tWf0aCPnd4/j0N5uRxXaJ0XbdY9erm1MBe31BCXEwwlVgVUBjp1auXoqOjVV1d7be9urpaqampVzwmNTU1oP0lyel0yul0BlJaq9yd0b/dzwEAAK4uoNk0sbGxGj16tIqLi33bPB6PiouLlZmZecVjMjMz/faXpKKiomb3BwAAkSXgbppFixZp9uzZuv322zV27FitXLlStbW1uu+++yRJeXl56tu3rwoKCiRJDz74oCZOnKgVK1Zo2rRp2rBhg/bs2aOXXnqpba8EAACEpYDDyMyZM/XFF1/oySefVFVVlUaOHKnt27f7BqlWVFQoKqqpwSUrK0vr16/Xz372M/30pz/VjTfeqE2bNmnYsGFtdxUAACBsBbzOiA2sMwIAQPhp6e9vnk0DAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArAp4OXgbvIvEulwuy5UAAICW8v7evtZi72ERRs6cOSNJSk9Pt1wJAAAI1JkzZ5SUlNTs52HxbBqPx6OTJ08qISFBDoejzb7X5XIpPT1dx44di4hn3nC9nRvX23lF0rVKXG9nYozRmTNn1KdPH7+H6P6tsGgZiYqK0vXXX99u35+YmNjp/gJcDdfbuXG9nVckXavE9XYWV2sR8WIAKwAAsIowAgAArIroMOJ0OrVkyRI5nU7bpXQIrrdz43o7r0i6VonrjURhMYAVAAB0XhHdMgIAAOwjjAAAAKsIIwAAwCrCCAAAsCpiwsiyZcuUlZWl+Ph4de/e/Yr7VFRUaNq0aYqPj1dycrIeeeQRNTY2+u1TUlKi2267TU6nU4MHD1ZhYWH7Fx+kkpISORyOK77+9Kc/SZI+//zzK37+/vvvW66+dQYMGHDZtTz99NN++3z44Ye68847FRcXp/T0dD3zzDOWqg3O559/rgceeEADBw5U165ddcMNN2jJkiWqr6/326cz3d9Vq1ZpwIABiouLU0ZGhj744APbJbWJgoICjRkzRgkJCUpOTlZubq4OHz7st8+kSZMuu4/z58+3VHHr/cu//Mtl13HzzTf7Pr9w4YIWLFig6667Tt26ddMPfvADVVdXW6w4OFf6N8nhcGjBggWSOs99ba2wWIG1LdTX12vGjBnKzMzUK6+8ctnnbrdb06ZNU2pqqnbv3q3Kykrl5eUpJiZGy5cvlyQdOXJE06ZN0/z58/Xaa6+puLhYc+bMUVpamnJycjr6klosKytLlZWVftueeOIJFRcX6/bbb/fbvmPHDt16662+99ddd12H1Ngeli5dqrlz5/reJyQk+P7b5XJpypQpys7O1po1a/TRRx/p/vvvV/fu3TVv3jwb5bbaoUOH5PF49OKLL2rw4ME6cOCA5s6dq9raWv3iF7/w27cz3N+NGzdq0aJFWrNmjTIyMrRy5Url5OTo8OHDSk5Otl1eUHbu3KkFCxZozJgxamxs1E9/+lNNmTJFn3zyib7xjW/49ps7d66WLl3qex8fH2+j3KDdeuut2rFjh+99ly5Nv5Iefvhhbd26Va+//rqSkpK0cOFCff/739d7771no9Sg/elPf5Lb7fa9P3DggO666y7NmDHDt62z3NdWMRFm3bp1Jikp6bLt27ZtM1FRUaaqqsq3bfXq1SYxMdHU1dUZY4x59NFHza233up33MyZM01OTk671tzW6uvrTe/evc3SpUt9244cOWIkmf3799srrA3179/fPP/8881+/sILL5gePXr47q0xxjz22GNmyJAhHVBd+3vmmWfMwIEDfe870/0dO3asWbBgge+92+02ffr0MQUFBRarah+nTp0ykszOnTt92yZOnGgefPBBe0W1kSVLlpgRI0Zc8bPTp0+bmJgY8/rrr/u2HTx40EgypaWlHVRh+3rwwQfNDTfcYDwejzGm89zX1oqYbpprKS0t1fDhw5WSkuLblpOTI5fLpY8//ti3T3Z2tt9xOTk5Ki0t7dBag/X222/rf/7nf3Tfffdd9tl3v/tdJScn64477tDbb79tobq28/TTT+u6667TqFGj9Oyzz/p1uZWWlmrChAmKjY31bfP+v+uvvvrKRrltqqamRj179rxse7jf3/r6eu3du9fv5zAqKkrZ2dlh93PYEjU1NZJ02b187bXX1KtXLw0bNkz5+fk6d+6cjfKC9te//lV9+vTRoEGDdPfdd6uiokKStHfvXjU0NPjd55tvvln9+vXrFPe5vr5er776qu6//36/h792lvvaGhHTTXMtVVVVfkFEku99VVXVVfdxuVw6f/68unbt2jHFBumVV15RTk6O38MHu3XrphUrVmj8+PGKiorSG2+8odzcXG3atEnf/e53LVbbOv/0T/+k2267TT179tTu3buVn5+vyspKPffcc5Iu3suBAwf6HXPp/e7Ro0eH19xWysvL9atf/cqvi6az3N8vv/xSbrf7ij+Hhw4dslRV+/B4PHrooYc0fvx4DRs2zLf9hz/8ofr3768+ffroww8/1GOPPabDhw/rzTfftFht4DIyMlRYWKghQ4aosrJSTz31lO68804dOHBAVVVVio2NvWx8X0pKiu/f43C2adMmnT59Wvfee69vW2e5r61mu2kmGI899piRdNXXwYMH/Y5prptm7ty5ZsqUKX7bamtrjSSzbds2Y4wxN954o1m+fLnfPlu3bjWSzLlz59r24lqgNdd/7NgxExUVZX77299e8/vvuecec8cdd7RX+QFrzfV6vfLKK6ZLly7mwoULxhhj7rrrLjNv3jy/fT7++GMjyXzyySftfi0t0ZrrPX78uLnhhhvMAw88cM3vD7X72xInTpwwkszu3bv9tj/yyCNm7NixlqpqH/Pnzzf9+/c3x44du+p+xcXFRpIpLy/voMrax1dffWUSExPNyy+/bF577TUTGxt72T5jxowxjz76qIXq2taUKVPMd77znavu01nua0uFdcvI4sWL/ZLllQwaNKhF35WamnrZiHzvyO3U1FTfn387mru6ulqJiYlWWkVac/3r1q3Tdddd16L/N5yRkaGioqJgSmxTwdzvjIwMNTY26vPPP9eQIUOavZdS0/22LdDrPXnypCZPnqysrCy99NJL1/z+ULu/LdGrVy9FR0df8d6Fyn1rCwsXLtSWLVu0a9cuvxbMK8nIyJB0sUXshhtu6Ijy2kX37t110003qby8XHfddZfq6+t1+vRpv9aRznCfjx49qh07dlyzxaOz3NeWCusw0rt3b/Xu3btNviszM1PLli3TqVOnfCPyi4qKlJiYqKFDh/r22bZtm99xRUVFyszMbJMaAhXo9RtjtG7dOt8soWspKytTWlpaMCW2qWDud1lZmaKionz3NjMzU48//rgaGhp8/1sUFRVpyJAhIdNFE8j1njhxQpMnT9bo0aO1bt06RUVdezhYqN3floiNjdXo0aNVXFys3NxcSRe7M4qLi7Vw4UK7xbUBY4x+/OMf66233lJJScllXYlXUlZWJklhdy//1tmzZ/Xpp5/qnnvu0ejRoxUTE6Pi4mL94Ac/kCQdPnxYFRUV1v69bSvr1q1TcnKypk2bdtX9Ost9bTHbTTMd5ejRo2b//v3mqaeeMt26dTP79+83+/fvN2fOnDHGGNPY2GiGDRtmpkyZYsrKysz27dtN7969TX5+vu87PvvsMxMfH28eeeQRc/DgQbNq1SoTHR1ttm/fbuuyArJjx45muzIKCwvN+vXrzcGDB83BgwfNsmXLTFRUlFm7dq2FSoOze/du8/zzz5uysjLz6aefmldffdX07t3b5OXl+fY5ffq0SUlJMffcc485cOCA2bBhg4mPjzcvvviixcpb5/jx42bw4MHm7/7u78zx48dNZWWl7+XVme7vhg0bjNPpNIWFheaTTz4x8+bNM927d/ebCReufvSjH5mkpCRTUlLidx+93cDl5eVm6dKlZs+ePebIkSNm8+bNZtCgQWbChAmWKw/c4sWLTUlJiTly5Ih57733THZ2tunVq5c5deqUMeZiN1W/fv3MO++8Y/bs2WMyMzNNZmam5aqD43a7Tb9+/cxjjz3mt70z3dfWipgwMnv27Cv2uf/+97/37fP555+bqVOnmq5du5pevXqZxYsXm4aGBr/v+f3vf29GjhxpYmNjzaBBg8y6des69kKCMGvWLJOVlXXFzwoLC80tt9xi4uPjTWJiohk7dqzftLpwsnfvXpORkWGSkpJMXFycueWWW8zy5ct940W8/vznP5s77rjDOJ1O07dvX/P0009bqjg469ata3ZMiVdnur/GGPOrX/3K9OvXz8TGxpqxY8ea999/33ZJbaK5++j9d6aiosJMmDDB9OzZ0zidTjN48GDzyCOPmJqaGruFt8LMmTNNWlqaiY2NNX379jUzZ870Gx9x/vx584//+I+mR48eJj4+3vz93/+9X8AOR7/73e+MJHP48GG/7Z3pvraWwxhjOrgxBgAAwId1RgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFb9f3fTeDt8yWOzAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exponentiation remains stable while $X <= 88$, after which the $Y$ value explodes and becomes unrepresentable:"
      ],
      "metadata": {
        "id": "FUATc9RUJBHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.exp(torch.tensor(88)), torch.exp(torch.tensor(89))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpYwUCSW0xNE",
        "outputId": "e4be419a-1bf6-467e-889b-113317f56cf2"
      },
      "execution_count": 569,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1.6516e+38), tensor(inf))"
            ]
          },
          "metadata": {},
          "execution_count": 569
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is an easy solution to this overflow problem though. Since the normalization step adjusts the distribution of values, the actual values passed to it are less important as long as their relative distribution remains the same.\n",
        "\n",
        "Notice how adding or subtracting constants from the logits tensor yields the same normalized result:"
      ],
      "metadata": {
        "id": "NvNtB23l1blG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for value in [0, -1, 1, -2, 2, -10, 10]:\n",
        "  result = _calc_probs(torch.tensor([-2.0, -3.0, 0.0, -5.0]) + value)\n",
        "  print(result[\"probs\"])"
      ],
      "metadata": {
        "id": "DGQER5OdBvWj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b99997f-f60f-4651-a909-f3b9d8ae02a4"
      },
      "execution_count": 570,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.1135, 0.0418, 0.8390, 0.0057])\n",
            "tensor([0.1135, 0.0418, 0.8390, 0.0057])\n",
            "tensor([0.1135, 0.0418, 0.8390, 0.0057])\n",
            "tensor([0.1135, 0.0418, 0.8390, 0.0057])\n",
            "tensor([0.1135, 0.0418, 0.8390, 0.0057])\n",
            "tensor([0.1135, 0.0418, 0.8390, 0.0057])\n",
            "tensor([0.1135, 0.0418, 0.8390, 0.0057])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore, to mitigate the numerical instability during exponentiation, we just need to subtract the maximum logit value from the tensor. This adjustment allows us to achieve the same result while avoiding overflow issues:"
      ],
      "metadata": {
        "id": "ImnEg-pmB4MA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_calc_probs(torch.tensor([-100.0, -3.0, 0.0, 100.0]) - 100.0)"
      ],
      "metadata": {
        "id": "A_wcUBkrCAd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9609c143-55fe-46fc-947b-e285b3813b2b"
      },
      "execution_count": 571,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'counts': tensor([0.0000e+00, 1.4013e-45, 3.7835e-44, 1.0000e+00]),\n",
              " 'probs': tensor([0.0000e+00, 1.4013e-45, 3.7835e-44, 1.0000e+00])}"
            ]
          },
          "metadata": {},
          "execution_count": 571
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `F.cross_entropy()` function in PyTorch enhances numerical stability by combining *log-softmax* and *negative log-likelihood* into one step. It subtracts the maximum logit before softmax to prevent overflow, ensuring stable and accurate results. Since not only more reliable but faster, we'll be using it instead from now on."
      ],
      "metadata": {
        "id": "ETX3YaKsCCOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train on Partial Dataset üèãÔ∏è‚Äç‚ôÇÔ∏è"
      ],
      "metadata": {
        "id": "_rJz6q9nCXV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create the model again to train it from scratch:"
      ],
      "metadata": {
        "id": "VgZpB27XCZcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()"
      ],
      "metadata": {
        "id": "SHLtZ7NyUxrC"
      },
      "execution_count": 572,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's define the training function and run it for a few steps:"
      ],
      "metadata": {
        "id": "jDaqKRPFCw0i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, model, n_steps, learning_rate=0.1, verbose=False):\n",
        "  for step in range(n_steps):\n",
        "    loss, logits = forward(dataset, model)\n",
        "    if verbose: print(f\"step: {step}, loss={loss}\")\n",
        "\n",
        "    # Perform backpropagation\n",
        "    for p in model: p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Perform gradient descent\n",
        "    for p in model: p.data -= learning_rate * p.grad\n",
        "\n",
        "  # Return loss and final logits\n",
        "  return loss, logits\n",
        "\n",
        "loss, _ = train(dataset, model, 10, learning_rate=1, verbose=True)\n",
        "loss"
      ],
      "metadata": {
        "id": "CaOP0l0aUX0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7f63e6-59a0-4e15-d042-13750606afc3"
      },
      "execution_count": 573,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss=17.775842666625977\n",
            "step: 1, loss=9.489405632019043\n",
            "step: 2, loss=6.31451940536499\n",
            "step: 3, loss=4.218498229980469\n",
            "step: 4, loss=3.1028294563293457\n",
            "step: 5, loss=1.657302975654602\n",
            "step: 6, loss=1.6401607990264893\n",
            "step: 7, loss=1.6740186214447021\n",
            "step: 8, loss=2.21173095703125\n",
            "step: 9, loss=1.4576846361160278\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.4577, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 573
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's converging, but you can start noticing some instability in the last few steps.\n",
        "\n",
        "Let's continue training with a lower learning rate:"
      ],
      "metadata": {
        "id": "xw6X2LFkDR2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, logits = train(dataset, model, 20, learning_rate=0.1, verbose=True)\n",
        "loss"
      ],
      "metadata": {
        "id": "t_z-djy9DTLS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "165363bd-d388-4aa6-d9b8-c56af4a4429b"
      },
      "execution_count": 574,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss=1.0502263307571411\n",
            "step: 1, loss=0.9460259079933167\n",
            "step: 2, loss=0.8787636160850525\n",
            "step: 3, loss=0.822243332862854\n",
            "step: 4, loss=0.7705267667770386\n",
            "step: 5, loss=0.7216517925262451\n",
            "step: 6, loss=0.6745641827583313\n",
            "step: 7, loss=0.6287581324577332\n",
            "step: 8, loss=0.5841146111488342\n",
            "step: 9, loss=0.5408188700675964\n",
            "step: 10, loss=0.49929147958755493\n",
            "step: 11, loss=0.46011513471603394\n",
            "step: 12, loss=0.42397618293762207\n",
            "step: 13, loss=0.39163923263549805\n",
            "step: 14, loss=0.36388885974884033\n",
            "step: 15, loss=0.34136030077934265\n",
            "step: 16, loss=0.3242487907409668\n",
            "step: 17, loss=0.3120889365673065\n",
            "step: 18, loss=0.3038617670536041\n",
            "step: 19, loss=0.29838013648986816\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.2984, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 574
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's easy to achieve a low loss because we are training a model with a lot of parameters on just a few examples. For this reason, the model can easily overfit the data. Interestingly, we can't reduce the loss to zero, suggesting that some sequences are not learnable.\n",
        "\n",
        "Let's retrieve the maximum logit activations for each example and compare them with the labels $Y$ to identify which sequences are being misclassified:"
      ],
      "metadata": {
        "id": "hHKObdn4CRvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(dim=1) # This returns the maximum value for each row (max along the columns dimension)"
      ],
      "metadata": {
        "id": "K4pqLx2ZVNO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "935c6901-7a45-4fe6-b1fd-d9fe3d9a3585"
      },
      "execution_count": 575,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(\n",
              "values=tensor([ 9.4951, 13.1345, 15.0723, 16.9269, 25.8626,  9.4951, 13.2594, 26.4025,\n",
              "        16.9143, 18.4625, 14.0319, 19.1883,  9.4951, 15.8460, 16.9449, 22.0483,\n",
              "         9.4951, 12.5316, 14.8274, 16.4057, 16.7011, 18.3765, 16.9052, 15.6323,\n",
              "        24.3389,  9.4951, 12.5404, 11.8761, 15.2975, 17.5801, 15.9891, 22.8013],\n",
              "       grad_fn=<MaxBackward0>),\n",
              "indices=tensor([ 9, 13, 13,  1,  0,  9, 12,  9, 22,  9,  1,  0,  9, 22,  1,  0,  9, 19,\n",
              "         1,  2,  5, 12, 12,  1,  0,  9, 15, 16,  8,  9,  1,  0]))"
            ]
          },
          "metadata": {},
          "execution_count": 575
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we not only obtained the maximum logit values for each example, but we also retrieved the indices where those values were found. Let's compare those indices with $Y$ side by side:"
      ],
      "metadata": {
        "id": "skflQZqPD2l6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits.max(1).indices, Y, logits.max(1).indices != Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yeRrpdcjCrCO",
        "outputId": "3168118c-5295-4948-c531-0e4193086689"
      },
      "execution_count": 576,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 9, 13, 13,  1,  0,  9, 12,  9, 22,  9,  1,  0,  9, 22,  1,  0,  9, 19,\n",
              "          1,  2,  5, 12, 12,  1,  0,  9, 15, 16,  8,  9,  1,  0]),\n",
              " tensor([ 5, 13, 13,  1,  0, 15, 12,  9, 22,  9,  1,  0,  1, 22,  1,  0,  9, 19,\n",
              "          1,  2,  5, 12, 12,  1,  0, 19, 15, 16,  8,  9,  1,  0]),\n",
              " tensor([ True, False, False, False, False,  True, False, False, False, False,\n",
              "         False, False,  True, False, False, False, False, False, False, False,\n",
              "         False, False, False, False, False,  True, False, False, False, False,\n",
              "         False, False]))"
            ]
          },
          "metadata": {},
          "execution_count": 576
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've identified the failed predictions, let's use some PyTorch advanced indexing to retrieve the mismatched input sequences.\n",
        "\n",
        "We can use a boolean tensor to specify which values we want to retrieve from another tensor:"
      ],
      "metadata": {
        "id": "Z_IIgMLXZWa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1, 2, 3, 4])[torch.tensor([True, False, True, False])]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFjxiinQZsu4",
        "outputId": "54538bc5-1ec0-43ee-9111-adc762bff71f"
      },
      "execution_count": 577,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 577
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our boolean tensor has a `True` for each input sequence where the next character was predicted incorrectly and `False` for correct predictions, we can use this tensor to index into the input tensor `X` and retrieve the corresponding values for all failed predictions:"
      ],
      "metadata": {
        "id": "EkvTBJ_2Z9Gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X[logits.max(1).indices != Y]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y4wiEYGOw3B",
        "outputId": "560445d4-d26c-473e-aec2-7c6469228453"
      },
      "execution_count": 578,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0],\n",
              "        [0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 578
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that `0` is the integer that encodes the *EOS character* `.`:"
      ],
      "metadata": {
        "id": "FrZ4rl-raeiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stoi_map['.']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xktHxWoUajRe",
        "outputId": "7809e8ab-93e6-4bfe-e8c0-1b9538d337bf"
      },
      "execution_count": 579,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 579
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore all of the missed predictions were caused by the character sequence `...`. This makes sense because that sequence can be followed by the first letter of any name in the dataset, making it impossible to predict with $100\\%$ accuracy."
      ],
      "metadata": {
        "id": "vkeHfPnbC57B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train on Full Dataset üöÄ"
      ],
      "metadata": {
        "id": "RTM-N3mqEKOH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's train on the entire dataset:"
      ],
      "metadata": {
        "id": "8v5qmNHTDPvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model() # Create model from scratch\n",
        "dataset = build_dataset(words) # Create dataset with all examples (not only a subset)\n",
        "X, Y = dataset # Unpack the dataset"
      ],
      "metadata": {
        "id": "x6RFv1jpVkX_"
      },
      "execution_count": 580,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll train for a few steps:"
      ],
      "metadata": {
        "id": "GArECqF5baIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, _ = train(dataset, model, 10, verbose=True)\n",
        "loss"
      ],
      "metadata": {
        "id": "av70Gvf6VzcC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ddaab52-414f-473d-f240-c01f123d42b7"
      },
      "execution_count": 581,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step: 0, loss=16.726470947265625\n",
            "step: 1, loss=14.942935943603516\n",
            "step: 2, loss=13.863014221191406\n",
            "step: 3, loss=13.003832817077637\n",
            "step: 4, loss=12.292207717895508\n",
            "step: 5, loss=11.732643127441406\n",
            "step: 6, loss=11.270576477050781\n",
            "step: 7, loss=10.859724044799805\n",
            "step: 8, loss=10.479724884033203\n",
            "step: 9, loss=10.136445045471191\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10.1364, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 581
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A solution to the problem of increased training time due to larger datasets is to use **Stochastic Gradient Descent (SGD)** instead of vanilla gradient descent. Instead of updating parameters based on the entire dataset, in each iteration, a mini-batch is sampled, and gradients are computed for that subset.\n",
        "\n",
        "This approach offers much better scalability, as training remains feasible as long as the batch size fits in memory, even with very large datasets. Although the gradients calculated from each mini-batch may not be perfect, they are still effective enough to guide the descent. This method has additional benefits, such as helping avoid local minima by introducing variation in the gradient at each step. This variability can also make overfitting less likely since an overfitted model typically is one that converged to a local minimum."
      ],
      "metadata": {
        "id": "47cBH26KDTWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a mini-batch, we randomly generate a list of indices corresponding to the batch size and retrieve the associated subset of the dataset. First, let's learn how to generate a random tensor with values within a specific range. For example, we can generate a tensor of shape $(10)$ with values in the range $[0,5]$:\n",
        "\n"
      ],
      "metadata": {
        "id": "6z0WP3ikb7uV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randint(0, 5, (10,))"
      ],
      "metadata": {
        "id": "av8k0v9hWBSD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57c8260b-3711-412e-af5b-010be41b7ab6"
      },
      "execution_count": 582,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 1, 3, 2, 3, 2, 4, 0, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 582
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's apply the same approach to our dataset. To sample a mini-batch of $32$ examples, we need a tensor of shape $(32)$ with values ranging from zero to the maximum index in the `X` input tensor, which corresponds to the first dimension of its shape:"
      ],
      "metadata": {
        "id": "DGC_GsIRFlIt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_indexes = torch.randint(0, X.shape[0], (32,))\n",
        "X.shape[0], len(batch_indexes), batch_indexes"
      ],
      "metadata": {
        "id": "BJup5ssHWFSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6dd5e88-c27f-4ff5-e517-7003b19a60ff"
      },
      "execution_count": 583,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(228146,\n",
              " 32,\n",
              " tensor([102653,  70454, 161541, 121652, 111574, 125988,  80159,  33049, 212482,\n",
              "          72000,  43887,  36030, 184134, 134115,  77447, 142283, 222782, 213097,\n",
              "         116753,  98019,  31424,  55789, 120850, 186081,  30630, 128744,  38183,\n",
              "         125341,  10651,  39416, 204288,  87622]))"
            ]
          },
          "metadata": {},
          "execution_count": 583
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, use those indices to retrieve the sampled mini-batch from the `X` input tensor:"
      ],
      "metadata": {
        "id": "OU9GnLDtFrVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xbt, Ybt = X[batch_indexes], Y[batch_indexes]\n",
        "Xbt.shape, Ybt.shape"
      ],
      "metadata": {
        "id": "XdpCKxvkFucu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10255d2-49bf-46d7-b02e-8e3be462cc62"
      },
      "execution_count": 584,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 3]), torch.Size([32]))"
            ]
          },
          "metadata": {},
          "execution_count": 584
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's modify the training function to implement *Stochastic Gradient Descent (SGD)* instead:"
      ],
      "metadata": {
        "id": "rY-KQXwMFyF7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataset, model, n_steps, learning_rate=0.1, batch_size=32, verbose=False):\n",
        "  # Unpack the dataset\n",
        "  X, Y = dataset\n",
        "\n",
        "  # Train for N steps\n",
        "  losses = []\n",
        "  for step in range(n_steps):\n",
        "    batch_indexes = torch.randint(0, X.shape[0], (batch_size,))\n",
        "    Xbt, Ybt = X[batch_indexes], Y[batch_indexes]\n",
        "    loss, logits = forward((Xbt, Ybt), model)\n",
        "    if verbose: print(f\"step: {step}, loss={loss}\")\n",
        "\n",
        "    # Perform backpropagation\n",
        "    for p in model: p.grad = None\n",
        "    loss.backward()\n",
        "\n",
        "    # Perform gradient descent\n",
        "    _learning_rate = learning_rate(step) if callable(learning_rate) else learning_rate\n",
        "    for p in model: p.data -= _learning_rate * p.grad\n",
        "\n",
        "    # Track stats\n",
        "    losses.append(loss.item())\n",
        "\n",
        "  return losses, logits\n",
        "\n",
        "model = build_model() # Create model from scratch\n",
        "losses, _ = train(dataset, model, 20_000) # Train for 20k steps on the entire dataset\n",
        "plt.plot(losses), losses[-1] # Plot the losses during training and output the loss at the last step"
      ],
      "metadata": {
        "id": "sYq6NxhKWKrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "outputId": "70d3d012-4c54-402e-c757-de44cc5d05e5"
      },
      "execution_count": 585,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.lines.Line2D at 0x7ae1907599f0>], 2.4568216800689697)"
            ]
          },
          "metadata": {},
          "execution_count": 585
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's evaluate the loss for the entire dataset (the losses we monitored during training were mini-batch losses):"
      ],
      "metadata": {
        "id": "s0ohzA6xtC9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, _ = forward(dataset, model)\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jazAsh7qtLQj",
        "outputId": "1ce5fa79-9716-42b1-ed77-129131dfd6f6"
      },
      "execution_count": 586,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4451, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 586
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We achieved a loss of $2.43$, which is already a great result! As a benchmark, the best loss we obtained for the simple model we trained in the previous notebook, [Character-Level Bigram Language Model](https://github.com/tsilva/aiml-notebooks/blob/main/002-character-level-bigram-language-model.ipynb), was $2.45$. This means we've already surpassed our previous attempt, and there's still room for improvement."
      ],
      "metadata": {
        "id": "8K9vzKJdU4sQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tune the Learning Rate üéõÔ∏è\n",
        "\n",
        "Selecting optimal learning rate is crucial for faster convergence and better results. Since the ideal learning rate can vary depending on the problem, a practical approach is to experiment with different values.\n",
        "\n",
        "Let's generate $1000$ learning rate exponents $e$ within the range $[-3, 0]$, and compute the corresponding learning rates, where the learning rate is given by $10^e$."
      ],
      "metadata": {
        "id": "jZ8GuqPRGXVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate_exponents = torch.linspace(-3, 0, 1000) # Generate 1000 exponents in range [-3, 0]\n",
        "learning_rates = 10**learning_rate_exponents # Calculate the learning rate for each exponent\n",
        "learning_rate_exponents[:5], learning_rates[:5] # Print a slice of the exponents and corresponding learning rates side by side"
      ],
      "metadata": {
        "id": "9H4b7KQFW3Aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f11ceb48-c176-41cc-9533-a54b6b13a36c"
      },
      "execution_count": 587,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-3.0000, -2.9970, -2.9940, -2.9910, -2.9880]),\n",
              " tensor([0.0010, 0.0010, 0.0010, 0.0010, 0.0010]))"
            ]
          },
          "metadata": {},
          "execution_count": 587
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll train a new model for $1000$ steps, selecting one of the calculated learning rates at each step. After training, we'll plot the loss against each corresponding learning rate exponent:"
      ],
      "metadata": {
        "id": "m2JbC3Jb0mc9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model() # Create the model from scratch to start with the untrained parameters\n",
        "losses, _ = train(dataset, model, 1000, learning_rate=lambda step:learning_rates[step]) # Train for 1k steps with a different learning rate at each step\n",
        "plt.plot(learning_rate_exponents, losses) # Plot the loss for each learning rate exponent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "SwUTdgtbvi5-",
        "outputId": "257876e0-922e-4fb1-c69a-a03c33aac7a6"
      },
      "execution_count": 588,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ae19075b6a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 588
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe the loss decreasing as the learning rate exponent increases. This is expected, as a higher exponent improves convergence speed, and each new learning rate is applied at the next step, allowing the model to naturally improve through backpropagation and gradient descent.\n",
        "\n",
        "What we're really interested in is the point just before the loss starts worsening as the exponent increases. According to the graph, the loss begins to worsen around an exponent of $-0.5$, suggesting that the optimal range is between $-1$ and $-0.5$.\n",
        "\n",
        "Thus, $-1$ is a strong candidate for the learning rate exponent, giving us a learning rate of $10^{-1} = 0.1$ (which is actually the default we started with)."
      ],
      "metadata": {
        "id": "ZCT_T3Rg0-Mo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's train for a while using that learning rate and see what loss we get on the entire dataset:"
      ],
      "metadata": {
        "id": "C3vF7ugr1o7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model() # Create fresh new model\n",
        "train(dataset, model, 20_000, learning_rate=10**-1) # Train for 20k steps with the learning rate we discovered\n",
        "loss = forward(dataset, model)[0] # Calculate the loss for the entire dataset\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l25f8dKVxyM9",
        "outputId": "a91ac11c-39fd-4528-c7d5-511c0cb94de1"
      },
      "execution_count": 589,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.4110, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 589
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We achieved a good loss, but let's make a small adjustment. Near the end of training, gradient descent might oscillate around a minimum if the learning rate is too high. To prevent this, we can decay the learning rate during the final steps.\n",
        "\n",
        "Let's try decaying the learning rate by an order of magnitude in the last $5000$ steps of training and see if we achieve a lower loss:"
      ],
      "metadata": {
        "id": "Y5QgiWDL1rbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model() # Create fresh new model\n",
        "train(dataset, model, 20_000, learning_rate=lambda step: 10**-1 if step < 15_000 else 10**-2) # Train for 15k steps with lr=0.1 and another 5k with lr=0.01\n",
        "loss = forward(dataset, model)[0] # Calculate the loss for the entire dataset\n",
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ7rT5Dt6tOu",
        "outputId": "8ad6a903-313a-4f59-9953-c6cfb4a09d81"
      },
      "execution_count": 590,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3592, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 590
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We achieved a lower loss this way, but let's not get carried away. As the loss decreases, the model may start overfitting, memorizing patterns rather than capturing their essence. This limits its ability to generate novel names that differ from the dataset."
      ],
      "metadata": {
        "id": "ePpEw9Ex7J41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train on Training Set üéØ\n",
        "\n",
        "To prevent overfitting, we need to split our dataset into three subsets:\n",
        "\n",
        "- **Training set:** Used to calculate the loss, perform *backpropagation*, and adjust model parameters during training.\n",
        "- **Validation set:** Used to calculate the loss without adjusting parameters. If the loss decreases on both the training and validation sets, it indicates that the model is generalizing well, rather than just memorizing the training data. The moment training loss keeps decreasing and validation loss starts increasing, it may mean that the model is starting to overfit the training set.\n",
        "- **Test set:** A small portion of the dataset reserved for final evaluation. It remains untouched during development to provide an unbiased assessment of the model's performance.\n",
        "\n",
        "Let's split our dataset into an $80/10/10$ ratio:"
      ],
      "metadata": {
        "id": "UPOzg38J772o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def build_split_dataset(words, block_size=BLOCK_SIZE):\n",
        "  # Shuffle the words so that the data splits are random\n",
        "  random.seed(SEED) # Set the RNG seed for reproducibility\n",
        "  words = words.copy() # Copy so we don't modify the original reference when shuffling\n",
        "  random.shuffle(words)\n",
        "\n",
        "  # Split the dataset\n",
        "  n1 = int(0.8*len(words)) # First data split point\n",
        "  n2 = int(0.9*len(words)) # Second data split point\n",
        "  training_set = build_dataset(words[:n1], block_size=block_size) # Create training set from range [0%-80%]\n",
        "  validation_set = build_dataset(words[n1:n2], block_size=block_size) # Create validation set from range [80%-90%]\n",
        "  test_set = build_dataset(words[n2:], block_size=block_size) # Create test set from range [90%-100%]\n",
        "\n",
        "  # Return the splits\n",
        "  return training_set, validation_set, test_set\n",
        "\n",
        "# Train on the training set, then calculate post-training loss using the validation set\n",
        "model = build_model() # Create fresh new model\n",
        "training_set, validation_set, test_set = build_split_dataset(words)\n",
        "train(training_set, model, 20_000, learning_rate=lambda step: 10**-1 if step < 15_000 else 10**-2) # Train on training set for 20k steps\n",
        "val_loss = forward(validation_set, model)[0] # Calculate validation loss\n",
        "val_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tl7smPt6Dch",
        "outputId": "0e745238-cb94-469c-84ca-0b8a8f35b86f"
      },
      "execution_count": 591,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3532, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 591
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a good loss on the *validation set*, let's check it on the *test set*:"
      ],
      "metadata": {
        "id": "zXzkNagRCW4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss = forward(test_set, model)[0] # Calculate test loss\n",
        "test_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-ZErhceCvXc",
        "outputId": "ea7d6e7e-132b-4073-8566-5602086bb5f0"
      },
      "execution_count": 592,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.3515, grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 592
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a test set loss of $2.36$, while in the previous notebook the best loss we achieved with access to the full dataset was $2.45$. This suggests that the current model is performing better, as the test loss was calculated on randomly sampled data that remained untouched until the final evaluation. This indicates that the model has likely learned patterns general to the domain represented by the dataset, rather than overfitting to the specific data in the training set.\n"
      ],
      "metadata": {
        "id": "2ACTCd3yC96N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample some Names ‚úçÔ∏è\n",
        "\n",
        "With our model trained, we can now generate names by predicting one character at a time. Starting with an empty context, the model predicts each next character until it reaches the *end-of-sequence character (EOS)*, forming a complete name. The model has learned patterns from real names, allowing it to create new, plausible names based on its character-level predictions.\n",
        "\n",
        "Let's check it out:"
      ],
      "metadata": {
        "id": "C0kPgAPtbf2a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_words(model, num_words, block_size=BLOCK_SIZE, seed=SEED):\n",
        "  C, W1, b1, W2, b2 = model # Unpack the model parameters\n",
        "  generator = torch.Generator().manual_seed(seed) # Use generator for reproducibility\n",
        "\n",
        "  # Sample N words\n",
        "  words = []\n",
        "  for _ in range(num_words):\n",
        "    char_indexes = []\n",
        "    context = [0] * block_size\n",
        "    while True:\n",
        "      emb = C[torch.tensor([context])] # Lookup embedding for character sequence\n",
        "      emb_reshaped = emb.view(1, -1) # Embedding has shape (1, block_size, embedding_size), we need to reshape to (1, block_size * embedding_size)\n",
        "      h = torch.tanh(emb_reshaped @ W1 + b1) # Forward pass through first layer\n",
        "      logits = h @ W2 + b2 # Forward pass through output layer to get the logits\n",
        "      probs = F.softmax(logits, dim=1) # Normalize the logits into a probability distribution\n",
        "      char_i = torch.multinomial(probs, num_samples=1, generator=generator).item() # Sample the next character using the probability distribution inferred from the last character sequence\n",
        "      context = context[1:] + [char_i] # Pop out oldest character and add sampled character to previous character sequence (FIFO queue)\n",
        "      char_indexes.append(char_i) # Add to list of sampled characters\n",
        "      if char_i == EOS_CHAR_INDEX: break # If EOS character was sampled, word is finished so break loop\n",
        "    word = \"\".join([itos_map[i] for i in char_indexes]) # Convert sampled character indexes back to characters and join to create word\n",
        "    words.append(word) # Add word to list of sampled words\n",
        "\n",
        "  # Return sampled words\n",
        "  return words\n",
        "\n",
        "sample_words(model, 20)"
      ],
      "metadata": {
        "id": "g6_Aykq6o7Gl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836e331a-9749-49c0-f396-0fcd1862a14e"
      },
      "execution_count": 593,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yeesyahne.',\n",
              " 'ame.',\n",
              " 'dleekhim.',\n",
              " 'mannya.',\n",
              " 'tryahdanten.',\n",
              " 'ena.',\n",
              " 'dayamiiah.',\n",
              " 'abkeles.',\n",
              " 'lon.',\n",
              " 'toy.',\n",
              " 'alitki.',\n",
              " 'pupolannezane.',\n",
              " 'savalad.',\n",
              " 'waina.',\n",
              " 'lun.',\n",
              " 'kayahn.',\n",
              " 'zeriagrten.',\n",
              " 'kirahmole.',\n",
              " 'eidinny.',\n",
              " 'rin.']"
            ]
          },
          "metadata": {},
          "execution_count": 593
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not too bad, but the generated names still don't sound quite right. You could try training the model for longer to improve the test loss, but it's likely that using only the previous $3$ characters won't be enough to predict the next one. It could also be that the embeddings need more dimensions to represent the characters more accurately. Perhaps both adjustments are necessary. Let's leave it as is for now, and we'll explore increasing the block size in the next notebook, along with other optimizations. By then, we'll have a fully cleaned-up and softcoded codebase to start with."
      ],
      "metadata": {
        "id": "L0tR06lebwPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore the Learned Embeddings üî¨\n",
        "\n",
        "Since the character embeddings are two-dimensional, we can easily visualize them.\n",
        "\n",
        "Let's plot them and see if we can spot some patterns:"
      ],
      "metadata": {
        "id": "nnwBj2oUesn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_embeddings(model):\n",
        "    # Unpack the model parameters (we only need the embedding matrix 'C' for plotting)\n",
        "    C = model[0]\n",
        "\n",
        "    # Set the size of the plot (8x8 inches), to make sure the points and labels are clear\n",
        "    plt.figure(figsize=(8, 8))\n",
        "\n",
        "    # Plot a scatter plot of the embeddings (C[:, 0] and C[:, 1] represent the x and y coordinates)\n",
        "    # 's=200' makes each point larger, so they are easier to see\n",
        "    plt.scatter(C[:, 0].data, C[:, 1].data, s=200)\n",
        "\n",
        "    # Loop over each embedding to plot the character it represents\n",
        "    for i in range(C.shape[0]):\n",
        "        # Add the text label (character) at the corresponding (x, y) coordinates\n",
        "        # 'ha=\"center\"' and 'va=\"center\"' center the label at each point\n",
        "        # 'color=\"white\"' ensures the text is visible on dark scatter points\n",
        "        plt.text(C[i, 0].item(), C[i, 1].item(), itos_map[i], ha=\"center\", va=\"center\", color=\"white\")\n",
        "\n",
        "    # Add a grid with minor lines for better visualization\n",
        "    plt.grid(\"minor\")\n",
        "\n",
        "plot_embeddings(model)"
      ],
      "metadata": {
        "id": "PYxzM_VbmRG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "1548c407-a9e0-4b51-ebec-7415904c543c"
      },
      "execution_count": 594,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The positioning of the character embeddings shows that the model has learned certain patterns by placing characters with similar properties closer together. Some patterns that stand out:\n",
        "\n",
        "- Vowels (`a`, `e`, `i`, `o`, `u`) are clustered together, suggesting the model has recognized that vowels behave differently from consonants. For example, consonant pairs (like `br` in \"Brian\") are more common than vowel pairs (like `ea` in \"Leah\") in American names.\n",
        "- The `.` character is isolated, likely because it only appears at the start or end of a name.\n",
        "- `y` is close to `i` because they are pronounced similarly and can sometimes be interchangeable.\n",
        "\n",
        "There may be more patterns in the plot‚Äîcan you spot any?"
      ],
      "metadata": {
        "id": "YmOFHtFae5lH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## THE END\n",
        "\n",
        "For more **AI/ML** notebooks, check my repo: üîó https://github.com/tsilva/aiml-notebooks"
      ],
      "metadata": {
        "id": "VqMdnJZAxZ5R"
      }
    }
  ]
}